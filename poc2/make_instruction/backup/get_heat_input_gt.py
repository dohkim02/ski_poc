import pandas as pd
import json
import ast
from collections import defaultdict
import numpy as np
import os
import sys

data_path = os.path.abspath("../")  # ì˜ˆ: í•œ ë‹¨ê³„ ë°”ê¹¥ í´ë”
sys.path.append(data_path)


class ExcelGroupProcessor:
    def __init__(self, file_path):
        """
        ì—‘ì…€ íŒŒì¼ì„ ì½ì–´ì„œ ì´ˆê¸°í™”

        Args:
            file_path (str): ì—‘ì…€ íŒŒì¼ ê²½ë¡œ
        """
        self.file_path = file_path
        self.df = None
        self.grouped_data = None

    def load_data(self):
        """ì—‘ì…€ íŒŒì¼ì„ ì½ì–´ì˜¤ê¸°"""
        try:
            # ì—‘ì…€ íŒŒì¼ í™•ì¥ìì— ë”°ë¼ ë‹¤ë¥´ê²Œ ì²˜ë¦¬
            if self.file_path.endswith(".csv"):
                self.df = pd.read_csv(self.file_path, encoding="utf-8")
            else:
                self.df = pd.read_excel(self.file_path)

            print(f"ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(self.df)}í–‰, {len(self.df.columns)}ì—´")
            print("ì»¬ëŸ¼ëª…:", list(self.df.columns))
            return True

        except Exception as e:
            print(f"íŒŒì¼ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return False

    def parse_usage_pattern(self, pattern_str):
        """
        ì‚¬ìš©ëŸ‰_íŒ¨í„´ ë¬¸ìì—´ì„ íŒŒì‹±í•˜ì—¬ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜

        Args:
            pattern_str (str): ì‚¬ìš©ëŸ‰ íŒ¨í„´ ë¬¸ìì—´

        Returns:
            dict: ì›”ë³„ ì‚¬ìš©ëŸ‰ ë”•ì…”ë„ˆë¦¬
        """
        try:
            # ë¬¸ìì—´ì´ ë”•ì…”ë„ˆë¦¬ í˜•íƒœì¸ ê²½ìš°
            if isinstance(pattern_str, str):
                # ì‘ì€ë”°ì˜´í‘œë¥¼ í°ë”°ì˜´í‘œë¡œ ë³€ê²½í•˜ì—¬ JSON íŒŒì‹± ê°€ëŠ¥í•˜ê²Œ ë§Œë“¤ê¸°
                pattern_str = pattern_str.replace("'", '"')
                return json.loads(pattern_str)
            elif isinstance(pattern_str, dict):
                return pattern_str
            else:
                return {}
        except:
            try:
                # ast.literal_evalì„ ì‚¬ìš©í•œ íŒŒì‹± ì‹œë„
                return ast.literal_eval(str(pattern_str))
            except:
                print(f"ì‚¬ìš©ëŸ‰ íŒ¨í„´ íŒŒì‹± ì‹¤íŒ¨: {pattern_str}")
                return {}

    def remove_outliers_iqr(self, values, multiplier=1.5):
        """
        IQR ë°©ë²•ì„ ì‚¬ìš©í•˜ì—¬ ì´ìƒì¹˜ ì œê±°

        Args:
            values (list): ê°’ë“¤ì˜ ë¦¬ìŠ¤íŠ¸
            multiplier (float): IQR ë°°ìˆ˜ (ê¸°ë³¸ê°’: 1.5)

        Returns:
            list: ì´ìƒì¹˜ê°€ ì œê±°ëœ ê°’ë“¤ì˜ ë¦¬ìŠ¤íŠ¸
        """
        if len(values) < 4:  # ê°’ì´ ë„ˆë¬´ ì ìœ¼ë©´ ì´ìƒì¹˜ ì œê±° ì•ˆ í•¨
            return values

        q1 = np.percentile(values, 25)
        q3 = np.percentile(values, 75)
        iqr = q3 - q1

        lower_bound = q1 - multiplier * iqr
        upper_bound = q3 + multiplier * iqr

        filtered_values = [v for v in values if lower_bound <= v <= upper_bound]

        # ì´ìƒì¹˜ê°€ ë°œê²¬ëœ ê²½ìš° ì •ë³´ ì¶œë ¥
        if len(filtered_values) < len(values):
            removed_count = len(values) - len(filtered_values)
            print(
                f"         - ì´ìƒì¹˜ {removed_count}ê°œ ì œê±°ë¨ (ì „ì²´ {len(values)}ê°œ ì¤‘)"
            )

        return filtered_values

    def calculate_monthly_stats_with_outlier_removal(
        self, usage_patterns, remove_outliers=False
    ):
        """
        ì´ìƒì¹˜ ì œê±° ì˜µì…˜ì„ í¬í•¨í•œ ì›”ë³„ ì¤‘ì•™ê°’ ê³„ì‚°

        Args:
            usage_patterns (list): ì‚¬ìš©ëŸ‰ íŒ¨í„´ ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸
            remove_outliers (bool): ì´ìƒì¹˜ ì œê±° ì—¬ë¶€

        Returns:
            tuple: (ì›”ë³„ ì¤‘ì•™ê°’, ì›”ë³„ IQR)
        """
        monthly_values = defaultdict(list)

        for pattern in usage_patterns:
            if isinstance(pattern, dict):
                for month, value in pattern.items():
                    try:
                        monthly_values[month].append(float(value))
                    except (ValueError, TypeError):
                        continue

        # ê° ì›”ë³„ ì¤‘ì•™ê°’ê³¼ IQR ê³„ì‚°
        monthly_medians = {}
        monthly_iqrs = {}

        for month, values in monthly_values.items():
            if values:
                # ì´ìƒì¹˜ ì œê±° ì˜µì…˜ ì ìš©
                if remove_outliers and len(values) >= 4:
                    original_count = len(values)
                    values = self.remove_outliers_iqr(values)
                    if len(values) < original_count:
                        print(
                            f"      ğŸ”§ {month}: ì´ìƒì¹˜ ì œê±° í›„ {len(values)}ê°œ ë°ì´í„° ì‚¬ìš© (ì›ë˜ {original_count}ê°œ)"
                        )

                # ì¤‘ì•™ê°’ ê³„ì‚°
                median_val = np.median(values)
                monthly_medians[month] = round(median_val, 2)

                # IQR ê³„ì‚° (Q3 - Q1)
                if len(values) >= 2:
                    q1 = np.percentile(values, 25)
                    q3 = np.percentile(values, 75)
                    iqr_val = q3 - q1
                    monthly_iqrs[month] = round(iqr_val, 2)

                    # ë””ë²„ê¹… ì •ë³´ ì¶œë ¥ (IQRì´ ì¤‘ì•™ê°’ì˜ 50% ì´ìƒì¸ ê²½ìš°)
                    if iqr_val > median_val * 0.5:
                        print(f"      âš ï¸  {month} ë†’ì€ ë³€ë™ì„± ê°ì§€:")
                        print(
                            f"         - ì¤‘ì•™ê°’: {median_val:.2f}, IQR: {iqr_val:.2f}"
                        )
                        print(f"         - ë°ì´í„° ê°œìˆ˜: {len(values)}ê°œ")
                        print(
                            f"         - ìµœì†Œê°’: {min(values):.2f}, ìµœëŒ€ê°’: {max(values):.2f}"
                        )
                        print(f"         - Q1: {q1:.2f}, Q3: {q3:.2f}")
                else:
                    monthly_iqrs[month] = 0.0

        return monthly_medians, monthly_iqrs

    def calculate_monthly_stats(self, usage_patterns):
        """
        ì—¬ëŸ¬ ì‚¬ìš©ëŸ‰ íŒ¨í„´ì˜ ì›”ë³„ ì¤‘ì•™ê°’ê³¼ IQRì„ ê³„ì‚°

        Args:
            usage_patterns (list): ì‚¬ìš©ëŸ‰ íŒ¨í„´ ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸

        Returns:
            tuple: (ì›”ë³„ ì¤‘ì•™ê°’, ì›”ë³„ IQR)
        """
        return self.calculate_monthly_stats_with_outlier_removal(
            usage_patterns, remove_outliers=False
        )

    # ìš©ë„ë³„ í‰ê· !!!!
    def group_and_calculate(self, group_column="ìš©ë„"):
        """
        ì§€ì •ëœ ì»¬ëŸ¼ì„ ê¸°ì¤€ìœ¼ë¡œ ê·¸ë£¹í™”í•˜ê³  í‰ê· ê°’ê³¼ í‘œì¤€í¸ì°¨ ê³„ì‚°

        Args:
            group_column (str): ê·¸ë£¹í™”í•  ì»¬ëŸ¼ëª…

        Returns:
            pd.DataFrame: ê·¸ë£¹í™”ëœ ê²°ê³¼ ë°ì´í„°í”„ë ˆì„
        """
        if self.df is None:
            print("ë°ì´í„°ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return None

        # í•„ìš”í•œ ì»¬ëŸ¼ë“¤ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
        required_columns = [group_column, "ì‚¬ìš©ëŸ‰_íŒ¨í„´"]
        missing_columns = [
            col for col in required_columns if col not in self.df.columns
        ]

        if missing_columns:
            print(f"í•„ìš”í•œ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤: {missing_columns}")
            return None

        # ê·¸ë£¹ë³„ë¡œ ë°ì´í„° ì²˜ë¦¬
        grouped_results = []

        for group_value, group_df in self.df.groupby(group_column):

            # ì‚¬ìš©ëŸ‰ íŒ¨í„´ íŒŒì‹± ë° í‰ê· , í‘œì¤€í¸ì°¨ ê³„ì‚°
            usage_patterns = []
            for pattern in group_df["ì‚¬ìš©ëŸ‰_íŒ¨í„´"]:
                parsed_pattern = self.parse_usage_pattern(pattern)
                if parsed_pattern:
                    usage_patterns.append(parsed_pattern)

            # ì›”ë³„ í‰ê·  ì‚¬ìš©ëŸ‰ê³¼ í‘œì¤€í¸ì°¨ ê³„ì‚°
            monthly_medians, monthly_iqrs = (
                self.calculate_monthly_stats_with_outlier_removal(usage_patterns)
            )

            # ê²°ê³¼ ì €ì¥
            grouped_results.append(
                {
                    group_column: group_value,
                    "ì‚¬ìš©ëŸ‰ íŒ¨í„´ ì¤‘ì•™ê°’": monthly_medians,
                    "ì‚¬ìš©ëŸ‰ íŒ¨í„´ IQR": monthly_iqrs,
                }
            )

        # ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜
        self.grouped_data = pd.DataFrame(grouped_results)

        print(f"ê·¸ë£¹í™” ì™„ë£Œ: {len(self.grouped_data)}ê°œ ê·¸ë£¹")
        return self.grouped_data

    # ë³´ì¼ëŸ¬, ì—°ì†Œê¸° ì—´ëŸ‰ ë³„ ê·¸ë£¹í™” ê¸°ì¤€
    def categorize_capacity(self, value):
        """
        ì—´ëŸ‰ê°’ì„ ë²”ìœ„ë³„ ì¹´í…Œê³ ë¦¬ë¡œ ë¶„ë¥˜

        Args:
            value (float): ì—´ëŸ‰ê°’

        Returns:
            str: ì¹´í…Œê³ ë¦¬ëª…
        """
        if pd.isna(value):
            return "ë¯¸ë¶„ë¥˜"
        elif value == 0:
            return "0"
        elif value < 10000:
            return "1~9999"
        elif value < 50000:
            return "10000~49999"
        elif value < 100000:
            return "50000~99999"
        else:
            return "100000 ì´ìƒ"

    # ë³´ì¼ëŸ¬, ì—°ì†Œê¸° ì—´ëŸ‰ ë³„ í‰ê·  ê³„ì‚°
    def group_by_capacity_and_calculate(self, remove_outliers=False):
        """
        ë³´ì¼ëŸ¬ ì—´ëŸ‰ê³¼ ì—°ì†Œê¸° ì—´ëŸ‰ì„ í•©ì³ì„œ ì´ ì—´ëŸ‰ì„ ê³„ì‚°í•˜ê³  ë²”ìœ„ë³„ë¡œ ê·¸ë£¹í™”í•˜ì—¬ ì›”ë³„ í‰ê· ê³¼ í‘œì¤€í¸ì°¨ ê³„ì‚°

        Args:
            remove_outliers (bool): ì´ìƒì¹˜ ì œê±° ì—¬ë¶€ (ê¸°ë³¸ê°’: False)

        Returns:
            pd.DataFrame: ì´ ì—´ëŸ‰ ê¸°ì¤€ìœ¼ë¡œ ê·¸ë£¹í™”ëœ ê²°ê³¼
        """
        if self.df is None:
            print("ë°ì´í„°ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return None

        # í•„ìš”í•œ ì»¬ëŸ¼ë“¤ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
        required_columns = ["ë³´ì¼ëŸ¬ ì—´ëŸ‰", "ì—°ì†Œê¸° ì—´ëŸ‰", "ì‚¬ìš©ëŸ‰_íŒ¨í„´"]
        missing_columns = [
            col for col in required_columns if col not in self.df.columns
        ]

        if missing_columns:
            print(f"í•„ìš”í•œ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤: {missing_columns}")
            return None

        print(f"ğŸ” ì›ë³¸ ë°ì´í„° ê°œìˆ˜: {len(self.df)}ê°œ")
        if remove_outliers:
            print("ğŸ“Š ì´ìƒì¹˜ ì œê±° ëª¨ë“œ í™œì„±í™”")

        # ë³´ì¼ëŸ¬ ì—´ëŸ‰ê³¼ ì—°ì†Œê¸° ì—´ëŸ‰ì„ í•©ì³ì„œ ì´ ì—´ëŸ‰ ê³„ì‚°
        print("ë³´ì¼ëŸ¬ ì—´ëŸ‰ê³¼ ì—°ì†Œê¸° ì—´ëŸ‰ì„ í•©ì³ì„œ ì´ ì—´ëŸ‰ ê³„ì‚° ì¤‘...")

        # ì›ë³¸ ë°ì´í„° ë¶„ì„
        boiler_na_count = self.df["ë³´ì¼ëŸ¬ ì—´ëŸ‰"].isna().sum()
        combustor_na_count = self.df["ì—°ì†Œê¸° ì—´ëŸ‰"].isna().sum()
        print(f"   - ë³´ì¼ëŸ¬ ì—´ëŸ‰ ê²°ì¸¡ê°’: {boiler_na_count}ê°œ")
        print(f"   - ì—°ì†Œê¸° ì—´ëŸ‰ ê²°ì¸¡ê°’: {combustor_na_count}ê°œ")

        self.df["ì´ì—´ëŸ‰"] = self.df["ë³´ì¼ëŸ¬ ì—´ëŸ‰"].fillna(0) + self.df[
            "ì—°ì†Œê¸° ì—´ëŸ‰"
        ].fillna(0)

        print(f"   - ì´ ì—´ëŸ‰ ê³„ì‚° í›„ ë°ì´í„° ê°œìˆ˜: {len(self.df)}ê°œ")

        # ì´ ì—´ëŸ‰ ê·¸ë£¹í™”
        print("ì´ ì—´ëŸ‰ ê¸°ì¤€ ê·¸ë£¹í™” ì¤‘...")
        self.df["ì´ì—´ëŸ‰_ê·¸ë£¹"] = self.df["ì´ì—´ëŸ‰"].apply(self.categorize_capacity)

        # ê·¸ë£¹ë³„ ê°œìˆ˜ í™•ì¸
        group_counts = self.df["ì´ì—´ëŸ‰_ê·¸ë£¹"].value_counts()
        print(f"   - ê·¸ë£¹ë³„ ë°ì´í„° ê°œìˆ˜:")
        for group, count in group_counts.items():
            print(f"     {group}: {count}ê°œ")

        # ì´ ì—´ëŸ‰ ê¸°ì¤€ìœ¼ë¡œ í†µê³„ ê³„ì‚° (ì´ìƒì¹˜ ì œê±° ì˜µì…˜ ì „ë‹¬)
        total_capacity_results = self._calculate_capacity_group_stats(
            "ì´ì—´ëŸ‰_ê·¸ë£¹", "ì´ì—´ëŸ‰", remove_outliers=remove_outliers
        )

        return total_capacity_results

    def _calculate_capacity_group_stats(
        self, group_column, capacity_column, remove_outliers=False
    ):
        """
        ìš©ëŸ‰ë³„ ê·¸ë£¹ì˜ í†µê³„ë¥¼ ê³„ì‚°í•˜ëŠ” ë‚´ë¶€ í•¨ìˆ˜

        Args:
            group_column (str): ê·¸ë£¹ ì»¬ëŸ¼ëª…
            capacity_column (str): ìš©ëŸ‰ ì»¬ëŸ¼ëª…
            remove_outliers (bool): ì´ìƒì¹˜ ì œê±° ì—¬ë¶€

        Returns:
            pd.DataFrame: ê·¸ë£¹í™”ëœ ê²°ê³¼ ë°ì´í„°í”„ë ˆì„
        """
        grouped_results = []
        total_processed = 0
        total_usage_patterns_parsed = 0

        for group_value, group_df in self.df.groupby(group_column):
            if len(group_df) == 0:
                continue

            print(f"   ğŸ“Š {group_value} ê·¸ë£¹ ì²˜ë¦¬ ì¤‘: {len(group_df)}ê°œ ë°ì´í„°")
            total_processed += len(group_df)

            # í•´ë‹¹ ìš©ëŸ‰ì˜ í‰ê· ê³¼ í‘œì¤€í¸ì°¨
            capacity_avg = group_df[capacity_column].mean()
            capacity_std = (
                group_df[capacity_column].std(ddof=0) if len(group_df) > 1 else 0.0
            )

            # ì‚¬ìš©ëŸ‰ íŒ¨í„´ íŒŒì‹± ë° í‰ê· , í‘œì¤€í¸ì°¨ ê³„ì‚°
            usage_patterns = []
            parsing_success_count = 0

            for pattern in group_df["ì‚¬ìš©ëŸ‰_íŒ¨í„´"]:
                parsed_pattern = self.parse_usage_pattern(pattern)
                if parsed_pattern:
                    usage_patterns.append(parsed_pattern)
                    parsing_success_count += 1

            print(
                f"      - ì‚¬ìš©ëŸ‰ íŒ¨í„´ íŒŒì‹± ì„±ê³µ: {parsing_success_count}/{len(group_df)}ê°œ"
            )
            total_usage_patterns_parsed += parsing_success_count

            # ì›”ë³„ í‰ê·  ì‚¬ìš©ëŸ‰ê³¼ í‘œì¤€í¸ì°¨ ê³„ì‚° (ì´ìƒì¹˜ ì œê±° ì˜µì…˜ ì ìš©)
            monthly_medians, monthly_iqrs = (
                self.calculate_monthly_stats_with_outlier_removal(
                    usage_patterns, remove_outliers=remove_outliers
                )
            )

            # ê²°ê³¼ ì €ì¥
            grouped_results.append(
                {
                    "ì—´ëŸ‰": group_value,
                    "ë°ì´í„°_ìˆ˜": len(group_df),
                    "ì‚¬ìš©ëŸ‰_íŒ¨í„´_ì¤‘ì•™ê°’": monthly_medians,
                    "ì‚¬ìš©ëŸ‰_íŒ¨í„´_IQR": monthly_iqrs,
                }
            )

        # ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜
        result_df = pd.DataFrame(grouped_results)

        print(f"ğŸ” ì²˜ë¦¬ ê²°ê³¼ ìš”ì•½:")
        print(f"   - ì´ ì²˜ë¦¬ëœ ë°ì´í„°: {total_processed}ê°œ")
        print(f"   - ì‚¬ìš©ëŸ‰ íŒ¨í„´ íŒŒì‹± ì„±ê³µ: {total_usage_patterns_parsed}ê°œ")
        print(f"   - {group_column} ê·¸ë£¹í™” ì™„ë£Œ: {len(result_df)}ê°œ ê·¸ë£¹")

        return result_df

    def display_capacity_group_results(self, results):
        """
        ì´ ì—´ëŸ‰ë³„ ê·¸ë£¹í™” ê²°ê³¼ë¥¼ í™”ë©´ì— ì¶œë ¥

        Args:
            results (pd.DataFrame): group_by_capacity_and_calculate í•¨ìˆ˜ì˜ ê²°ê³¼
        """
        if results is None:
            print("ê·¸ë£¹í™”ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        print(f"\n{'='*80}")
        print(f"                    ì´ ì—´ëŸ‰ ë²”ìœ„ë³„ ê·¸ë£¹í™” ê²°ê³¼")
        print(f"{'='*80}")

        for idx, (_, row) in enumerate(results.iterrows(), 1):
            group_name = row["ì—´ëŸ‰"]
            data_count = row["ë°ì´í„°_ìˆ˜"]

            print(f"\n[{idx}] ì—´ëŸ‰: {group_name} (ë°ì´í„° ìˆ˜: {data_count}ê°œ)")
            print("-" * 60)

            monthly_avg_data = row["ì‚¬ìš©ëŸ‰_íŒ¨í„´_ì¤‘ì•™ê°’"]
            monthly_std_data = row["ì‚¬ìš©ëŸ‰_íŒ¨í„´_IQR"]

            if isinstance(monthly_avg_data, dict) and isinstance(
                monthly_std_data, dict
            ):
                print(f"ğŸ“ˆ ì›”ë³„ ì‚¬ìš©ëŸ‰ (ì¤‘ì•™ê°’, IQR):")

                # ë¶„ê¸°ë³„ë¡œ ë‚˜ëˆ„ì–´ ì¶œë ¥
                quarters = [
                    ["1ì›”", "2ì›”", "3ì›”"],  # 1ë¶„ê¸°
                    ["4ì›”", "5ì›”", "6ì›”"],  # 2ë¶„ê¸°
                    ["7ì›”", "8ì›”", "9ì›”"],  # 3ë¶„ê¸°
                    ["10ì›”", "11ì›”", "12ì›”"],  # 4ë¶„ê¸°
                ]

                for quarter_idx, quarter in enumerate(quarters, 1):
                    quarter_data = []
                    for month in quarter:
                        avg_val = monthly_avg_data.get(month, 0)
                        std_val = monthly_std_data.get(month, 0)
                        quarter_data.append(
                            f"{month}: {avg_val:>7.2f}(Â±{std_val:>6.2f})"
                        )

                    print(f"   {quarter_idx}ë¶„ê¸°: {' | '.join(quarter_data)}")

        print(f"\n{'='*80}")

    def save_capacity_groups_to_excel(self, results, output_path):
        """
        ì´ ì—´ëŸ‰ë³„ ê·¸ë£¹í™” ê²°ê³¼ë¥¼ ì—‘ì…€ íŒŒì¼ë¡œ ì €ì¥

        Args:
            results (pd.DataFrame): ì´ ì—´ëŸ‰ ê·¸ë£¹í™” ê²°ê³¼
            output_path (str): ì €ì¥í•  íŒŒì¼ ê²½ë¡œ

        Returns:
            bool: ì €ì¥ ì„±ê³µ ì—¬ë¶€
        """
        if results is None:
            print("ê·¸ë£¹í™”ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return False

        try:
            # ê·¸ë£¹í™” ê²°ê³¼ë¥¼ ê°„ë‹¨í•œ í˜•íƒœë¡œ ì €ì¥
            expanded_data = []

            for _, row in results.iterrows():
                new_row = {
                    "ì—´ëŸ‰": row["ì—´ëŸ‰"],
                    "ë°ì´í„°_ìˆ˜": row["ë°ì´í„°_ìˆ˜"],
                    "ì‚¬ìš©ëŸ‰_íŒ¨í„´_median": row[
                        "ì‚¬ìš©ëŸ‰_íŒ¨í„´_ì¤‘ì•™ê°’"
                    ],  # ë”•ì…”ë„ˆë¦¬ í˜•íƒœë¡œ ì €ì¥ (ì¤‘ì•™ê°’)
                    "ì‚¬ìš©ëŸ‰_íŒ¨í„´_IQR": row[
                        "ì‚¬ìš©ëŸ‰_íŒ¨í„´_IQR"
                    ],  # ë”•ì…”ë„ˆë¦¬ í˜•íƒœë¡œ ì €ì¥ (IQR)
                }
                expanded_data.append(new_row)

            result_df = pd.DataFrame(expanded_data)

            # ì—‘ì…€ íŒŒì¼ë¡œ ì €ì¥
            result_df.to_excel(output_path, index=False, engine="openpyxl")

            print(f"ê²°ê³¼ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {output_path}")
            print(f"ì´ {len(result_df)}ê°œ ê·¸ë£¹ì˜ ë°ì´í„°ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
            print("ğŸ“Š ì €ì¥ëœ ì»¬ëŸ¼:")
            print("   - ì—´ëŸ‰: ì´ ì—´ëŸ‰ êµ¬ê°„")
            print("   - ë°ì´í„°_ìˆ˜: í•´ë‹¹ êµ¬ê°„ì˜ ë°ì´í„° ê°œìˆ˜")
            print("   - ì‚¬ìš©ëŸ‰_íŒ¨í„´_median: ì›”ë³„ ì‚¬ìš©ëŸ‰ ì¤‘ì•™ê°’ (ë”•ì…”ë„ˆë¦¬)")
            print("   - ì‚¬ìš©ëŸ‰_íŒ¨í„´_IQR: ì›”ë³„ ì‚¬ìš©ëŸ‰ IQR (ë”•ì…”ë„ˆë¦¬)")
            return True

        except Exception as e:
            print(f"íŒŒì¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return False

    def display_results(self):
        """
        ìš©ë„ë³„ ê·¸ë£¹í™” ê²°ê³¼ë¥¼ í™”ë©´ì— ì¶œë ¥
        """
        if self.grouped_data is None:
            print("ê·¸ë£¹í™”ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        print(f"\n{'='*80}")
        print(f"                    ìš©ë„ë³„ ê·¸ë£¹í™” ê²°ê³¼")
        print(f"{'='*80}")

        for idx, (_, row) in enumerate(self.grouped_data.iterrows(), 1):
            group_column_name = self.grouped_data.columns[0]
            group_name = row[group_column_name]

            print(f"\n[{idx}] {group_column_name}: {group_name}")
            print("-" * 60)

            monthly_avg_data = row["ì‚¬ìš©ëŸ‰ íŒ¨í„´ ì¤‘ì•™ê°’"]
            monthly_std_data = row["ì‚¬ìš©ëŸ‰ íŒ¨í„´ IQR"]

            if isinstance(monthly_avg_data, dict) and isinstance(
                monthly_std_data, dict
            ):
                print(f"ğŸ“ˆ ì›”ë³„ ì‚¬ìš©ëŸ‰ (ì¤‘ì•™ê°’, IQR):")

                # ë¶„ê¸°ë³„ë¡œ ë‚˜ëˆ„ì–´ ì¶œë ¥
                quarters = [
                    ["1ì›”", "2ì›”", "3ì›”"],  # 1ë¶„ê¸°
                    ["4ì›”", "5ì›”", "6ì›”"],  # 2ë¶„ê¸°
                    ["7ì›”", "8ì›”", "9ì›”"],  # 3ë¶„ê¸°
                    ["10ì›”", "11ì›”", "12ì›”"],  # 4ë¶„ê¸°
                ]

                for quarter_idx, quarter in enumerate(quarters, 1):
                    quarter_data = []
                    for month in quarter:
                        avg_val = monthly_avg_data.get(month, 0)
                        std_val = monthly_std_data.get(month, 0)
                        quarter_data.append(
                            f"{month}: {avg_val:>7.2f}(Â±{std_val:>6.2f})"
                        )

                    print(f"   {quarter_idx}ë¶„ê¸°: {' | '.join(quarter_data)}")

        print(f"\n{'='*80}")


def convert_df_to_dict(obj):
    if isinstance(obj, pd.DataFrame):
        return obj.to_dict()
    elif isinstance(obj, list):
        return [convert_df_to_dict(item) for item in obj]
    elif isinstance(obj, dict):
        return {k: convert_df_to_dict(v) for k, v in obj.items()}
    else:
        return obj


# ìš©ë„ ë³„ ê·¸ë£¹í™”
def main(input_file, output_file, group_name, gt_json_path):
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    # í”„ë¡œì„¸ì„œ ì´ˆê¸°í™”
    processor = ExcelGroupProcessor(input_file)

    # ë°ì´í„° ë¡œë“œ
    if not processor.load_data():
        return

    # ê·¸ë£¹í™” ë° í‰ê· /í‘œì¤€í¸ì°¨ ê³„ì‚°
    result = processor.group_and_calculate(group_column=group_name)
    results_serializable = convert_df_to_dict(result)
    # JSON íŒŒì¼ë¡œ ì €ì¥

    with open(gt_json_path, "w", encoding="utf-8") as f:
        json.dump(results_serializable, f, ensure_ascii=False, indent=4)

    print(f"JSON íŒŒì¼ë¡œ ì €ì¥ ì™„ë£Œ: {gt_json_path}")

    return processor


def main_capacity_grouping(input_file, output_file, remove_outliers=False):
    """
    ì´ ì—´ëŸ‰ë³„ ê·¸ë£¹í™” ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜

    Args:
        input_file (str): ì…ë ¥ ì—‘ì…€ íŒŒì¼ ê²½ë¡œ
        output_file (str): ì¶œë ¥ ì—‘ì…€ íŒŒì¼ ê²½ë¡œ
        remove_outliers (bool): ì´ìƒì¹˜ ì œê±° ì—¬ë¶€ (ê¸°ë³¸ê°’: False)
    """
    print("ğŸ”¥ ì´ ì—´ëŸ‰(ë³´ì¼ëŸ¬+ì—°ì†Œê¸°) ë²”ìœ„ë³„ ê·¸ë£¹í™” ì‹œì‘...")
    if remove_outliers:
        print("ğŸ“Š ì´ìƒì¹˜ ì œê±° ëª¨ë“œë¡œ ì‹¤í–‰")
    print("=" * 80)

    # í”„ë¡œì„¸ì„œ ì´ˆê¸°í™”
    processor = ExcelGroupProcessor(input_file)

    # ë°ì´í„° ë¡œë“œ
    if not processor.load_data():
        print("âŒ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨")
        return None

    # ì´ ì—´ëŸ‰ë³„ ê·¸ë£¹í™” ì‹¤í–‰ (ì´ìƒì¹˜ ì œê±° ì˜µì…˜ ì „ë‹¬)
    capacity_results = processor.group_by_capacity_and_calculate(
        remove_outliers=remove_outliers
    )

    if capacity_results is None:
        print("âŒ ì´ ì—´ëŸ‰ë³„ ê·¸ë£¹í™” ì‹¤íŒ¨")
        return None

    # ê²°ê³¼ í™”ë©´ ì¶œë ¥
    processor.display_capacity_group_results(capacity_results)

    # ì—‘ì…€ íŒŒì¼ë¡œ ì €ì¥
    if processor.save_capacity_groups_to_excel(capacity_results, output_file):
        print(f"âœ… ì´ ì—´ëŸ‰ë³„ ê·¸ë£¹í™” ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {output_file}")
    else:
        print("âŒ íŒŒì¼ ì €ì¥ ì‹¤íŒ¨")

    return processor, capacity_results


if __name__ == "__main__":
    print("=" * 80)
    print("          Excel ë°ì´í„° ê·¸ë£¹í™” ë° í†µê³„ ë¶„ì„ í”„ë¡œê·¸ë¨")
    print("=" * 80)

    # ê¸°ë³¸ ì„¤ì •
    input_file = "./data2_preprocessed.xlsx"

    # 1. ê¸°ì¡´ ìš©ë„ë³„ ê·¸ë£¹í™” ì‹¤í–‰
    print("\nğŸ¢ 1ë‹¨ê³„: ìš©ë„ë³„ ê·¸ë£¹í™” ì‹¤í–‰...")
    output_file = "./data2_biz_with_std.xlsx"
    gt_json_path = "./biz_group_gt.json"
    group_name = "ê·¸ë£¹"
    processor = main(input_file, output_file, group_name, gt_json_path)

    if processor:
        print("âœ… ìš©ë„ë³„ ê·¸ë£¹í™” ì™„ë£Œ")
        processor.display_results()

    print("\n" + "=" * 80)

    # 2. ìƒˆë¡œìš´ ìš©ëŸ‰ë³„ ê·¸ë£¹í™” ì‹¤í–‰
    print("\nğŸ”¥ 2ë‹¨ê³„: ì´ ì—´ëŸ‰ë³„ ê·¸ë£¹í™” ì‹¤í–‰...")
    capacity_output_file = "./capacity_groups_analysis.xlsx"
    processor_capacity, capacity_results = main_capacity_grouping(
        input_file, capacity_output_file, remove_outliers=False
    )

    if capacity_results is not None:
        print("âœ… ì´ ì—´ëŸ‰ë³„ ê·¸ë£¹í™” ì™„ë£Œ (ê¸°ë³¸ ëª¨ë“œ)")

        # ì¶”ê°€ ë¶„ì„ ì •ë³´ ì¶œë ¥
        print(f"\nğŸ“Š ë¶„ì„ ì™„ë£Œ ìš”ì•½:")
        print(f"   - ì´ ì—´ëŸ‰ ê·¸ë£¹: {len(capacity_results)}ê°œ")
        print(f"   - ê²°ê³¼ íŒŒì¼: {capacity_output_file}")

    print("\n" + "=" * 80)

    # 3. ì´ìƒì¹˜ ì œê±° ëª¨ë“œë¡œ ë‹¤ì‹œ ì‹¤í–‰
    print("\nğŸ”¥ 3ë‹¨ê³„: ì´ ì—´ëŸ‰ë³„ ê·¸ë£¹í™” ì‹¤í–‰ (ì´ìƒì¹˜ ì œê±° ëª¨ë“œ)...")
    capacity_output_file_clean = "./capacity_groups_analysis_clean.xlsx"
    processor_capacity_clean, capacity_results_clean = main_capacity_grouping(
        input_file, capacity_output_file_clean, remove_outliers=True
    )

    if capacity_results_clean is not None:
        print("âœ… ì´ ì—´ëŸ‰ë³„ ê·¸ë£¹í™” ì™„ë£Œ (ì´ìƒì¹˜ ì œê±° ëª¨ë“œ)")

        # ì¶”ê°€ ë¶„ì„ ì •ë³´ ì¶œë ¥
        print(f"\nğŸ“Š ì´ìƒì¹˜ ì œê±° ëª¨ë“œ ë¶„ì„ ì™„ë£Œ ìš”ì•½:")
        print(f"   - ì´ ì—´ëŸ‰ ê·¸ë£¹: {len(capacity_results_clean)}ê°œ")
        print(f"   - ê²°ê³¼ íŒŒì¼: {capacity_output_file_clean}")
        print(f"   - ë‘ ê²°ê³¼ë¥¼ ë¹„êµí•˜ì—¬ í‘œì¤€í¸ì°¨ ë³€í™”ë¥¼ í™•ì¸í•˜ì„¸ìš”!")

    print("\n" + "=" * 80)
    print("           ëª¨ë“  ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤! ğŸ‰")
    print("=" * 80)
