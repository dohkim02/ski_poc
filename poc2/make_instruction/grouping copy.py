import pandas as pd
import json
import ast
from collections import defaultdict
import numpy as np
import os
import sys

data_path = os.path.abspath("../")  # ì˜ˆ: í•œ ë‹¨ê³„ ë°”ê¹¥ í´ë”
sys.path.append(data_path)

# utils ëª¨ë“ˆì—ì„œ ì—´ëŸ‰ ë²”ìœ„ ë¶„ë¥˜ í•¨ìˆ˜ import
from utils import get_heat_input_gt


class ExcelGroupProcessor:
    def __init__(self, file_path):
        """
        ì—‘ì…€ íŒŒì¼ì„ ì½ì–´ì„œ ì´ˆê¸°í™”

        Args:
            file_path (str): ì—‘ì…€ íŒŒì¼ ê²½ë¡œ
        """
        self.file_path = file_path
        self.df = None
        self.grouped_data = None

    def load_data(self):
        """ì—‘ì…€ íŒŒì¼ì„ ì½ì–´ì˜¤ê¸°"""
        try:
            # ì—‘ì…€ íŒŒì¼ í™•ì¥ìì— ë”°ë¼ ë‹¤ë¥´ê²Œ ì²˜ë¦¬
            if self.file_path.endswith(".csv"):
                self.df = pd.read_csv(self.file_path, encoding="utf-8")
            else:
                self.df = pd.read_excel(self.file_path)

            print(f"ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(self.df)}í–‰, {len(self.df.columns)}ì—´")
            print("ì»¬ëŸ¼ëª…:", list(self.df.columns))
            return True

        except Exception as e:
            print(f"íŒŒì¼ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return False

    def parse_usage_pattern(self, pattern_str):
        """
        ì‚¬ìš©ëŸ‰_íŒ¨í„´ ë¬¸ìì—´ì„ íŒŒì‹±í•˜ì—¬ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜

        Args:
            pattern_str (str): ì‚¬ìš©ëŸ‰ íŒ¨í„´ ë¬¸ìì—´

        Returns:
            dict: ì›”ë³„ ì‚¬ìš©ëŸ‰ ë”•ì…”ë„ˆë¦¬
        """
        try:
            # ë¬¸ìì—´ì´ ë”•ì…”ë„ˆë¦¬ í˜•íƒœì¸ ê²½ìš°
            if isinstance(pattern_str, str):
                # ì‘ì€ë”°ì˜´í‘œë¥¼ í°ë”°ì˜´í‘œë¡œ ë³€ê²½í•˜ì—¬ JSON íŒŒì‹± ê°€ëŠ¥í•˜ê²Œ ë§Œë“¤ê¸°
                pattern_str = pattern_str.replace("'", '"')
                return json.loads(pattern_str)
            elif isinstance(pattern_str, dict):
                return pattern_str
            else:
                return {}
        except:
            try:
                # ast.literal_evalì„ ì‚¬ìš©í•œ íŒŒì‹± ì‹œë„
                return ast.literal_eval(str(pattern_str))
            except:
                print(f"ì‚¬ìš©ëŸ‰ íŒ¨í„´ íŒŒì‹± ì‹¤íŒ¨: {pattern_str}")
                return {}

    def remove_outliers_iqr(self, values, multiplier=1.5):
        """
        IQR ë°©ë²•ì„ ì‚¬ìš©í•˜ì—¬ ì´ìƒì¹˜ ì œê±°

        Args:
            values (list): ê°’ë“¤ì˜ ë¦¬ìŠ¤íŠ¸
            multiplier (float): IQR ë°°ìˆ˜ (ê¸°ë³¸ê°’: 1.5)

        Returns:
            list: ì´ìƒì¹˜ê°€ ì œê±°ëœ ê°’ë“¤ì˜ ë¦¬ìŠ¤íŠ¸
        """
        if len(values) < 4:  # ê°’ì´ ë„ˆë¬´ ì ìœ¼ë©´ ì´ìƒì¹˜ ì œê±° ì•ˆ í•¨
            return values

        q1 = np.percentile(values, 25)
        q3 = np.percentile(values, 75)
        iqr = q3 - q1

        lower_bound = q1 - multiplier * iqr
        upper_bound = q3 + multiplier * iqr

        filtered_values = [v for v in values if lower_bound <= v <= upper_bound]

        # ì´ìƒì¹˜ê°€ ë°œê²¬ëœ ê²½ìš° ì •ë³´ ì¶œë ¥
        if len(filtered_values) < len(values):
            removed_count = len(values) - len(filtered_values)
            print(
                f"         - ì´ìƒì¹˜ {removed_count}ê°œ ì œê±°ë¨ (ì „ì²´ {len(values)}ê°œ ì¤‘)"
            )

        return filtered_values

    def calculate_monthly_stats_with_outlier_removal(
        self, usage_patterns, remove_outliers=False
    ):
        """
        ì´ìƒì¹˜ ì œê±° ì˜µì…˜ì„ í¬í•¨í•œ ì›”ë³„ ì¤‘ì•™ê°’ ê³„ì‚°

        Args:
            usage_patterns (list): ì‚¬ìš©ëŸ‰ íŒ¨í„´ ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸
            remove_outliers (bool): ì´ìƒì¹˜ ì œê±° ì—¬ë¶€

        Returns:
            tuple: (ì›”ë³„ ì¤‘ì•™ê°’, ì›”ë³„ IQR)
        """
        monthly_values = defaultdict(list)

        for pattern in usage_patterns:
            if isinstance(pattern, dict):
                for month, value in pattern.items():
                    try:
                        monthly_values[month].append(float(value))
                    except (ValueError, TypeError):
                        continue

        # ê° ì›”ë³„ ì¤‘ì•™ê°’ê³¼ IQR ê³„ì‚°
        monthly_medians = {}
        monthly_iqrs = {}

        for month, values in monthly_values.items():
            if values:
                # ì´ìƒì¹˜ ì œê±° ì˜µì…˜ ì ìš©
                if remove_outliers and len(values) >= 4:
                    original_count = len(values)
                    values = self.remove_outliers_iqr(values)
                    if len(values) < original_count:
                        print(
                            f"      ğŸ”§ {month}: ì´ìƒì¹˜ ì œê±° í›„ {len(values)}ê°œ ë°ì´í„° ì‚¬ìš© (ì›ë˜ {original_count}ê°œ)"
                        )

                # ì¤‘ì•™ê°’ ê³„ì‚°
                median_val = np.median(values)
                monthly_medians[month] = round(median_val, 2)

                # IQR ê³„ì‚° (Q3 - Q1)
                if len(values) >= 2:
                    q1 = np.percentile(values, 25)
                    q3 = np.percentile(values, 75)
                    iqr_val = q3 - q1
                    monthly_iqrs[month] = round(iqr_val, 2)

                    # ë””ë²„ê¹… ì •ë³´ ì¶œë ¥ (IQRì´ ì¤‘ì•™ê°’ì˜ 50% ì´ìƒì¸ ê²½ìš°)
                    if iqr_val > median_val * 0.5:
                        print(f"      âš ï¸  {month} ë†’ì€ ë³€ë™ì„± ê°ì§€:")
                        print(
                            f"         - ì¤‘ì•™ê°’: {median_val:.2f}, IQR: {iqr_val:.2f}"
                        )
                        print(f"         - ë°ì´í„° ê°œìˆ˜: {len(values)}ê°œ")
                        print(
                            f"         - ìµœì†Œê°’: {min(values):.2f}, ìµœëŒ€ê°’: {max(values):.2f}"
                        )
                        print(f"         - Q1: {q1:.2f}, Q3: {q3:.2f}")
                else:
                    monthly_iqrs[month] = 0.0

        return monthly_medians, monthly_iqrs

    def calculate_monthly_stats(self, usage_patterns):
        """
        ì—¬ëŸ¬ ì‚¬ìš©ëŸ‰ íŒ¨í„´ì˜ ì›”ë³„ ì¤‘ì•™ê°’ê³¼ IQRì„ ê³„ì‚°

        Args:
            usage_patterns (list): ì‚¬ìš©ëŸ‰ íŒ¨í„´ ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸

        Returns:
            tuple: (ì›”ë³„ ì¤‘ì•™ê°’, ì›”ë³„ IQR)
        """
        return self.calculate_monthly_stats_with_outlier_removal(
            usage_patterns, remove_outliers=False
        )

    def check_group_combinations(self, group_columns):
        """
        ê·¸ë£¹í™”í•  ì»¬ëŸ¼ë“¤ì˜ ê³ ìœ í•œ ì¡°í•© ê°œìˆ˜ì™€ ë‚´ìš©ì„ í™•ì¸

        Args:
            group_columns (list): ê·¸ë£¹í™”í•  ì»¬ëŸ¼ëª… ë¦¬ìŠ¤íŠ¸
        """
        if self.df is None:
            print("ë°ì´í„°ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return

        # ê³ ìœ í•œ ì¡°í•© í™•ì¸
        unique_combinations = self.df[group_columns].drop_duplicates()
        combination_count = len(unique_combinations)

        print(f"\nğŸ“Š ê·¸ë£¹í™” ì¡°í•© ë¶„ì„:")
        print(f"   - ê·¸ë£¹í™” ê¸°ì¤€: {', '.join(group_columns)}")
        print(f"   - ì´ ê³ ìœ í•œ ì¡°í•© ê°œìˆ˜: {combination_count}ê°œ")

        # ê° ì»¬ëŸ¼ë³„ ê³ ìœ ê°’ ê°œìˆ˜ë„ í‘œì‹œ
        for col in group_columns:
            unique_values = self.df[col].nunique()
            print(f"   - '{col}' ê³ ìœ ê°’ ê°œìˆ˜: {unique_values}ê°œ")

        # ì¡°í•©ì´ ë„ˆë¬´ ë§ì§€ ì•Šìœ¼ë©´ ì¼ë¶€ ì˜ˆì‹œ í‘œì‹œ
        if combination_count <= 20:
            print(f"\nğŸ“‹ ëª¨ë“  ì¡°í•©:")
            for idx, (_, row) in enumerate(unique_combinations.iterrows(), 1):
                combo_str = " | ".join([f"{col}: {row[col]}" for col in group_columns])
                # ê° ì¡°í•©ë³„ ë°ì´í„° ê°œìˆ˜ë„ í‘œì‹œ
                count = len(
                    self.df[(self.df[group_columns] == row[group_columns]).all(axis=1)]
                )
                print(f"   [{idx:2d}] {combo_str} ({count}ê°œ ë°ì´í„°)")
        else:
            print(f"\nğŸ“‹ ì¡°í•© ì˜ˆì‹œ (ì²˜ìŒ 10ê°œ):")
            for idx, (_, row) in enumerate(unique_combinations.head(10).iterrows(), 1):
                combo_str = " | ".join([f"{col}: {row[col]}" for col in group_columns])
                count = len(
                    self.df[(self.df[group_columns] == row[group_columns]).all(axis=1)]
                )
                print(f"   [{idx:2d}] {combo_str} ({count}ê°œ ë°ì´í„°)")
            print(f"   ... (ì´ {combination_count}ê°œ ì¡°í•©)")

        return combination_count

    def create_heat_group_column(self):
        """
        ì—´ëŸ‰ ì»¬ëŸ¼ì„ ê¸°ë°˜ìœ¼ë¡œ ì—´ëŸ‰ ë²”ìœ„ ê·¸ë£¹ì„ ìƒì„±í•˜ê³ ,
        'ì—´ëŸ‰ë²”ìœ„_ê·¸ë£¹_ìš©ë„' í˜•íƒœì˜ ìƒˆë¡œìš´ ì»¬ëŸ¼ì„ ì¶”ê°€
        """
        if self.df is None:
            print("ë°ì´í„°ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return False

        # í•„ìš”í•œ ì»¬ëŸ¼ë“¤ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
        required_columns = ["ì—´ëŸ‰", "ê·¸ë£¹", "ìš©ë„"]
        missing_columns = [
            col for col in required_columns if col not in self.df.columns
        ]

        if missing_columns:
            print(f"í•„ìš”í•œ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤: {missing_columns}")
            return False

        # ì—´ëŸ‰ ë²”ìœ„ ê·¸ë£¹ ìƒì„±
        self.df["ì—´ëŸ‰ë²”ìœ„"] = self.df["ì—´ëŸ‰"].apply(
            lambda x: get_heat_input_gt(x) if pd.notna(x) else "Unknown"
        )

        # ì—´ëŸ‰ë²”ìœ„_ê·¸ë£¹_ìš©ë„ ì¡°í•© ì»¬ëŸ¼ ìƒì„±
        self.df["ì—´ëŸ‰ë²”ìœ„_ê·¸ë£¹_ìš©ë„"] = (
            self.df["ì—´ëŸ‰ë²”ìœ„"].astype(str)
            + "_"
            + self.df["ê·¸ë£¹"].astype(str)
            + "_"
            + self.df["ìš©ë„"].astype(str)
        )

        print(f"âœ… ì—´ëŸ‰ ë²”ìœ„ ê·¸ë£¹í™” ì™„ë£Œ")
        print(f"   - ìƒì„±ëœ ì—´ëŸ‰ ë²”ìœ„: {self.df['ì—´ëŸ‰ë²”ìœ„'].value_counts().to_dict()}")

        return True

    # ìš©ë„ë³„ í‰ê· !!!!

    def group_and_calculate_with_heat(self, group_columns=["ì—´ëŸ‰ë²”ìœ„", "ê·¸ë£¹", "ìš©ë„"]):
        """
        ì—´ëŸ‰ ë²”ìœ„ë¥¼ í¬í•¨í•œ ì§€ì •ëœ ì»¬ëŸ¼ë“¤ì„ ê¸°ì¤€ìœ¼ë¡œ ê·¸ë£¹í™”í•˜ê³  í‰ê· ê°’ê³¼ í‘œì¤€í¸ì°¨ ê³„ì‚°

        Args:
            group_columns (list): ê·¸ë£¹í™”í•  ì»¬ëŸ¼ëª… ë¦¬ìŠ¤íŠ¸

        Returns:
            pd.DataFrame: ê·¸ë£¹í™”ëœ ê²°ê³¼ ë°ì´í„°í”„ë ˆì„
        """
        if self.df is None:
            print("ë°ì´í„°ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return None

        # ì—´ëŸ‰ ë²”ìœ„ ì»¬ëŸ¼ ìƒì„±
        if not self.create_heat_group_column():
            return None

        # í•„ìš”í•œ ì»¬ëŸ¼ë“¤ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
        required_columns = group_columns + ["ì‚¬ìš©ëŸ‰_íŒ¨í„´"]
        missing_columns = [
            col for col in required_columns if col not in self.df.columns
        ]

        if missing_columns:
            print(f"í•„ìš”í•œ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤: {missing_columns}")
            return None

        # ê·¸ë£¹ë³„ë¡œ ë°ì´í„° ì²˜ë¦¬
        grouped_results = []

        for group_value, group_df in self.df.groupby(group_columns):
            # ë‹¤ì¤‘ ì»¬ëŸ¼ ê·¸ë£¹í™”ì˜ ê²½ìš° group_valueê°€ íŠœí”Œì´ë¯€ë¡œ ì²˜ë¦¬
            if isinstance(group_value, tuple):
                group_info = dict(zip(group_columns, group_value))
            else:
                group_info = {group_columns[0]: group_value}

            # ì‚¬ìš©ëŸ‰ íŒ¨í„´ íŒŒì‹± ë° í‰ê· , í‘œì¤€í¸ì°¨ ê³„ì‚°
            usage_patterns = []
            for pattern in group_df["ì‚¬ìš©ëŸ‰_íŒ¨í„´"]:
                parsed_pattern = self.parse_usage_pattern(pattern)
                if parsed_pattern:
                    usage_patterns.append(parsed_pattern)

            # ì›”ë³„ í‰ê·  ì‚¬ìš©ëŸ‰ê³¼ í‘œì¤€í¸ì°¨ ê³„ì‚°
            monthly_medians, monthly_iqrs = (
                self.calculate_monthly_stats_with_outlier_removal(usage_patterns)
            )

            # ê²°ê³¼ ì €ì¥ (ê·¸ë£¹ ì •ë³´ì™€ í†µê³„ ì •ë³´ í¬í•¨)
            result_dict = group_info.copy()
            result_dict.update(
                {
                    "ì‚¬ìš©ëŸ‰ íŒ¨í„´ ì¤‘ì•™ê°’": monthly_medians,
                    "ì‚¬ìš©ëŸ‰ íŒ¨í„´ IQR": monthly_iqrs,
                    "ë°ì´í„° ê°œìˆ˜": len(group_df),
                }
            )
            grouped_results.append(result_dict)

        # ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜
        self.grouped_data = pd.DataFrame(grouped_results)

        print(f"ê·¸ë£¹í™” ì™„ë£Œ: {len(self.grouped_data)}ê°œ ê·¸ë£¹")
        print(f"ê·¸ë£¹í™” ê¸°ì¤€: {', '.join(group_columns)}")
        return self.grouped_data

    def display_results(self):
        """
        ê·¸ë£¹í™” ê²°ê³¼ë¥¼ í™”ë©´ì— ì¶œë ¥ (ë‹¤ì¤‘ ì»¬ëŸ¼ ì§€ì›)
        """
        if self.grouped_data is None:
            print("ê·¸ë£¹í™”ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        print(f"\n{'='*80}")
        print(f"                    ê·¸ë£¹í™” ê²°ê³¼")
        print(f"{'='*80}")

        for idx, (_, row) in enumerate(self.grouped_data.iterrows(), 1):
            # ê·¸ë£¹ ì •ë³´ ì¶”ì¶œ (í†µê³„ ê´€ë ¨ ì»¬ëŸ¼ ì œì™¸)
            group_info = {}
            for col in self.grouped_data.columns:
                if col not in ["ì‚¬ìš©ëŸ‰ íŒ¨í„´ ì¤‘ì•™ê°’", "ì‚¬ìš©ëŸ‰ íŒ¨í„´ IQR", "ë°ì´í„° ê°œìˆ˜"]:
                    group_info[col] = row[col]

            print(f"\n[{idx}] ", end="")
            group_parts = [f"{k}: {v}" for k, v in group_info.items()]
            print(" | ".join(group_parts))

            # ë°ì´í„° ê°œìˆ˜ ì •ë³´ ì¶”ê°€
            if "ë°ì´í„° ê°œìˆ˜" in row:
                print(f"     ğŸ“Š ë°ì´í„° ê°œìˆ˜: {row['ë°ì´í„° ê°œìˆ˜']}ê°œ")

            print("-" * 60)

            monthly_avg_data = row["ì‚¬ìš©ëŸ‰ íŒ¨í„´ ì¤‘ì•™ê°’"]
            monthly_std_data = row["ì‚¬ìš©ëŸ‰ íŒ¨í„´ IQR"]

            if isinstance(monthly_avg_data, dict) and isinstance(
                monthly_std_data, dict
            ):
                print(f"ğŸ“ˆ ì›”ë³„ ì‚¬ìš©ëŸ‰ (ì¤‘ì•™ê°’, IQR):")

                # ë¶„ê¸°ë³„ë¡œ ë‚˜ëˆ„ì–´ ì¶œë ¥
                quarters = [
                    ["1ì›”", "2ì›”", "3ì›”"],  # 1ë¶„ê¸°
                    ["4ì›”", "5ì›”", "6ì›”"],  # 2ë¶„ê¸°
                    ["7ì›”", "8ì›”", "9ì›”"],  # 3ë¶„ê¸°
                    ["10ì›”", "11ì›”", "12ì›”"],  # 4ë¶„ê¸°
                ]

                for quarter_idx, quarter in enumerate(quarters, 1):
                    quarter_data = []
                    for month in quarter:
                        avg_val = monthly_avg_data.get(month, 0)
                        std_val = monthly_std_data.get(month, 0)
                        quarter_data.append(
                            f"{month}: {avg_val:>7.2f}(Â±{std_val:>6.2f})"
                        )

                    print(f"   {quarter_idx}ë¶„ê¸°: {' | '.join(quarter_data)}")

        print(f"\n{'='*80}")


def convert_df_to_dict(obj):
    if isinstance(obj, pd.DataFrame):
        return obj.to_dict()
    elif isinstance(obj, list):
        return [convert_df_to_dict(item) for item in obj]
    elif isinstance(obj, dict):
        return {k: convert_df_to_dict(v) for k, v in obj.items()}
    else:
        return obj


# ìš©ë„ ë³„ ê·¸ë£¹í™”
def main(input_file, output_file, group_columns, gt_json_path):
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    # í”„ë¡œì„¸ì„œ ì´ˆê¸°í™”
    processor = ExcelGroupProcessor(input_file)

    # ë°ì´í„° ë¡œë“œ
    if not processor.load_data():
        return

    # ê·¸ë£¹í™” ë° í‰ê· /í‘œì¤€í¸ì°¨ ê³„ì‚°
    result = processor.group_and_calculate(group_columns=group_columns)
    results_serializable = convert_df_to_dict(result)
    # JSON íŒŒì¼ë¡œ ì €ì¥

    with open(gt_json_path, "w", encoding="utf-8") as f:
        json.dump(results_serializable, f, ensure_ascii=False, indent=4)

    print(f"JSON íŒŒì¼ë¡œ ì €ì¥ ì™„ë£Œ: {gt_json_path}")

    return processor


# ì—´ëŸ‰ ë²”ìœ„ë¥¼ ê³ ë ¤í•œ ê·¸ë£¹í™”
def main_with_heat(input_file, output_file, group_columns, gt_json_path):
    """ì—´ëŸ‰ ë²”ìœ„ë¥¼ ê³ ë ¤í•œ ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    # í”„ë¡œì„¸ì„œ ì´ˆê¸°í™”
    processor = ExcelGroupProcessor(input_file)

    # ë°ì´í„° ë¡œë“œ
    if not processor.load_data():
        return

    # ì—´ëŸ‰ ë²”ìœ„ë¥¼ ê³ ë ¤í•œ ê·¸ë£¹í™” ë° í‰ê· /í‘œì¤€í¸ì°¨ ê³„ì‚°
    result = processor.group_and_calculate_with_heat(group_columns=group_columns)
    results_serializable = convert_df_to_dict(result)

    # JSON íŒŒì¼ë¡œ ì €ì¥
    with open(gt_json_path, "w", encoding="utf-8") as f:
        json.dump(results_serializable, f, ensure_ascii=False, indent=4)

    print(f"JSON íŒŒì¼ë¡œ ì €ì¥ ì™„ë£Œ: {gt_json_path}")

    return processor


if __name__ == "__main__":
    print("=" * 80)
    print("          Excel ë°ì´í„° ê·¸ë£¹í™” ë° í†µê³„ ë¶„ì„ í”„ë¡œê·¸ë¨")
    print("=" * 80)

    # ê¸°ë³¸ ì„¤ì •
    input_file = "./group_biz_with_12.xlsx"

    # ì—´ëŸ‰ ë²”ìœ„ë¥¼ ê³ ë ¤í•œ ê·¸ë£¹í™” ì‹¤í–‰
    print("\nğŸ”¥ ì—´ëŸ‰ ë²”ìœ„ë¥¼ ê³ ë ¤í•œ ê·¸ë£¹ê³¼ ìš©ë„ë³„ ê·¸ë£¹í™” ì‹¤í–‰...")
    output_file_heat = "./group_biz_with_usage_heat.xlsx"
    gt_json_path_heat = "./group_biz_with_usage_heat.json"
    group_columns_heat = ["ì—´ëŸ‰ë²”ìœ„", "ê·¸ë£¹", "ìš©ë„"]  # ì—´ëŸ‰ë²”ìœ„, ê·¸ë£¹, ìš©ë„ë¡œ ê·¸ë£¹í™”
    processor_heat = main_with_heat(
        input_file, output_file_heat, group_columns_heat, gt_json_path_heat
    )

    if processor_heat:
        print("âœ… ì—´ëŸ‰ ë²”ìœ„ë¥¼ ê³ ë ¤í•œ ê·¸ë£¹ê³¼ ìš©ë„ë³„ ê·¸ë£¹í™” ì™„ë£Œ")
        processor_heat.display_results()

    print("\n" + "=" * 80)
    print("           ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤! ğŸ‰")
    print("=" * 80)
