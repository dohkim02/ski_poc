import pandas as pd
import json
import ast
from collections import defaultdict
import numpy as np
import os
import sys
from scipy import stats
from scipy.stats import jarque_bera, skew, kurtosis

data_path = os.path.abspath("../")  # ì˜ˆ: í•œ ë‹¨ê³„ ë°”ê¹¥ í´ë”
sys.path.append(data_path)

# utils ëª¨ë“ˆì—ì„œ ì—´ëŸ‰ ë²”ìœ„ ë¶„ë¥˜ í•¨ìˆ˜ import
from utils import get_heat_input_gt


class ExcelGroupProcessor:
    def __init__(self, file_path):
        """
        ì—‘ì…€ íŒŒì¼ì„ ì½ì–´ì„œ ì´ˆê¸°í™”

        Args:
            file_path (str): ì—‘ì…€ íŒŒì¼ ê²½ë¡œ
        """
        self.file_path = file_path
        self.df = None
        self.grouped_data = None

    def load_data(self):
        """ì—‘ì…€ íŒŒì¼ì„ ì½ì–´ì˜¤ê¸°"""
        try:
            # ì—‘ì…€ íŒŒì¼ í™•ì¥ìì— ë”°ë¼ ë‹¤ë¥´ê²Œ ì²˜ë¦¬
            if self.file_path.endswith(".csv"):
                self.df = pd.read_csv(self.file_path, encoding="utf-8")
            else:
                self.df = pd.read_excel(self.file_path)

            print(f"ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(self.df)}í–‰, {len(self.df.columns)}ì—´")
            print("ì»¬ëŸ¼ëª…:", list(self.df.columns))
            return True

        except Exception as e:
            print(f"íŒŒì¼ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return False

    def parse_usage_pattern(self, pattern_str):
        """
        ì‚¬ìš©ëŸ‰_íŒ¨í„´ ë¬¸ìì—´ì„ íŒŒì‹±í•˜ì—¬ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜

        Args:
            pattern_str (str): ì‚¬ìš©ëŸ‰ íŒ¨í„´ ë¬¸ìì—´

        Returns:
            dict: ì›”ë³„ ì‚¬ìš©ëŸ‰ ë”•ì…”ë„ˆë¦¬
        """
        try:
            # ë¬¸ìì—´ì´ ë”•ì…”ë„ˆë¦¬ í˜•íƒœì¸ ê²½ìš°
            if isinstance(pattern_str, str):
                # ì‘ì€ë”°ì˜´í‘œë¥¼ í°ë”°ì˜´í‘œë¡œ ë³€ê²½í•˜ì—¬ JSON íŒŒì‹± ê°€ëŠ¥í•˜ê²Œ ë§Œë“¤ê¸°
                pattern_str = pattern_str.replace("'", '"')
                return json.loads(pattern_str)
            elif isinstance(pattern_str, dict):
                return pattern_str
            else:
                return {}
        except:
            try:
                # ast.literal_evalì„ ì‚¬ìš©í•œ íŒŒì‹± ì‹œë„
                return ast.literal_eval(str(pattern_str))
            except:
                print(f"ì‚¬ìš©ëŸ‰ íŒ¨í„´ íŒŒì‹± ì‹¤íŒ¨: {pattern_str}")
                return {}

    def remove_outliers_iqr(self, values, multiplier=1.5):
        """
        IQR ë°©ë²•ì„ ì‚¬ìš©í•˜ì—¬ ì´ìƒì¹˜ ì œê±°

        Args:
            values (list): ê°’ë“¤ì˜ ë¦¬ìŠ¤íŠ¸
            multiplier (float): IQR ë°°ìˆ˜ (ê¸°ë³¸ê°’: 1.5)

        Returns:
            list: ì´ìƒì¹˜ê°€ ì œê±°ëœ ê°’ë“¤ì˜ ë¦¬ìŠ¤íŠ¸
        """
        if len(values) < 4:  # ê°’ì´ ë„ˆë¬´ ì ìœ¼ë©´ ì´ìƒì¹˜ ì œê±° ì•ˆ í•¨
            return values

        q1 = np.percentile(values, 25)
        q3 = np.percentile(values, 75)
        iqr = q3 - q1

        lower_bound = q1 - multiplier * iqr
        upper_bound = q3 + multiplier * iqr

        filtered_values = [v for v in values if lower_bound <= v <= upper_bound]

        # ì´ìƒì¹˜ê°€ ë°œê²¬ëœ ê²½ìš° ì •ë³´ ì¶œë ¥
        if len(filtered_values) < len(values):
            removed_count = len(values) - len(filtered_values)
            print(
                f"         - ì´ìƒì¹˜ {removed_count}ê°œ ì œê±°ë¨ (ì „ì²´ {len(values)}ê°œ ì¤‘)"
            )

        return filtered_values

    def analyze_distribution(self, values):
        """
        ë°ì´í„°ì˜ ë¶„í¬ë¥¼ ë¶„ì„í•˜ì—¬ ìµœì ì˜ í†µê³„ëŸ‰ ê²°ì •

        Args:
            values (list): ë¶„ì„í•  ê°’ë“¤ì˜ ë¦¬ìŠ¤íŠ¸

        Returns:
            dict: ë¶„í¬ ë¶„ì„ ê²°ê³¼ì™€ ê¶Œì¥ í†µê³„ëŸ‰
        """
        if len(values) < 3:
            return {
                "method": "median",
                "reason": "insufficient_data",
                "normality_p": None,
                "skewness": None,
                "mad_ratio": None,
            }

        values = np.array(values)

        # ì •ê·œì„± ê²€ì • (Jarque-Bera test)
        try:
            jb_stat, jb_p = jarque_bera(values)
        except:
            jb_p = 0.0

        # ì¹˜ìš°ì¹¨ ì¸¡ì •
        skewness = skew(values)

        # MAD ê³„ì‚° ë° ë³€ë™ì„± ì¸¡ì •
        median_val = np.median(values)
        mad = np.median(np.abs(values - median_val))
        mad_ratio = mad / median_val if median_val != 0 else 0

        # ê²°ì • ë¡œì§
        if jb_p > 0.05:  # ì •ê·œë¶„í¬ì— ê°€ê¹Œì›€
            method = "trimmed_mean"
            reason = "normal_distribution"
        elif abs(skewness) > 1.0:  # ì¹˜ìš°ì¹œ ë¶„í¬
            method = "median"
            reason = "skewed_distribution"
        elif mad_ratio > 0.5:  # ë³€ë™ì„±ì´ í¼
            method = "mad_adjusted"
            reason = "high_variability"
        else:  # ê¸°ë³¸ê°’
            method = "trimmed_mean"
            reason = "default_choice"

        return {
            "method": method,
            "reason": reason,
            "normality_p": jb_p,
            "skewness": skewness,
            "mad_ratio": mad_ratio,
        }

    def calculate_trimmed_mean(self, values, trim_percent=0.1):
        """
        ì ˆì‚­í‰ê·  ê³„ì‚°

        Args:
            values (list): ê°’ë“¤ì˜ ë¦¬ìŠ¤íŠ¸
            trim_percent (float): ì ˆì‚­ ë¹„ìœ¨ (ê° ëì—ì„œ ì œê±°í•  ë¹„ìœ¨)

        Returns:
            float: ì ˆì‚­í‰ê· 
        """
        return stats.trim_mean(values, trim_percent * 2)  # scipyëŠ” ì–‘ìª½ í•©ê³„ë¥¼ ë°›ìŒ

    def calculate_mad_adjusted_center(self, values):
        """
        MAD ê¸°ë°˜ ì¡°ì •ëœ ì¤‘ì‹¬ê°’ ê³„ì‚°

        Args:
            values (list): ê°’ë“¤ì˜ ë¦¬ìŠ¤íŠ¸

        Returns:
            float: MAD ì¡°ì •ëœ ì¤‘ì‹¬ê°’
        """
        median_val = np.median(values)
        mad = np.median(np.abs(values - median_val))

        # MAD ê¸°ë°˜ robustí•œ ì¤‘ì‹¬ê°’ ê³„ì‚°
        # ì¤‘ì•™ê°’ ì£¼ë³€ 1.5*MAD ë²”ìœ„ì˜ ê°’ë“¤ë§Œ ì‚¬ìš©í•˜ì—¬ í‰ê·  ê³„ì‚°
        mad_threshold = 1.5 * mad
        robust_values = [v for v in values if abs(v - median_val) <= mad_threshold]

        if len(robust_values) > 0:
            return np.mean(robust_values)
        else:
            return median_val

    def calculate_adaptive_monthly_stats(self, usage_patterns, remove_outliers=False):
        """
        ë¶„í¬ ë¶„ì„ ê¸°ë°˜ ì ì‘í˜• ì›”ë³„ í†µê³„ ê³„ì‚°

        Args:
            usage_patterns (list): ì‚¬ìš©ëŸ‰ íŒ¨í„´ ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸
            remove_outliers (bool): ì´ìƒì¹˜ ì œê±° ì—¬ë¶€

        Returns:
            tuple: (ì›”ë³„ ê¸°ì¤€ê°’, ì›”ë³„ ë³€ë™ì„± ì§€í‘œ, ì›”ë³„ ë¶„ì„ ì •ë³´)
        """
        monthly_values = defaultdict(list)

        for pattern in usage_patterns:
            if isinstance(pattern, dict):
                for month, value in pattern.items():
                    try:
                        monthly_values[month].append(float(value))
                    except (ValueError, TypeError):
                        continue

        # ê° ì›”ë³„ ìµœì í™”ëœ í†µê³„ëŸ‰ ê³„ì‚°
        monthly_references = {}
        monthly_variabilities = {}
        monthly_analysis = {}

        for month, values in monthly_values.items():
            if values:
                # ì´ìƒì¹˜ ì œê±° ì˜µì…˜ ì ìš©
                if remove_outliers and len(values) >= 4:
                    original_count = len(values)
                    values = self.remove_outliers_iqr(values)
                    if len(values) < original_count:
                        print(
                            f"      ğŸ”§ {month}: ì´ìƒì¹˜ ì œê±° í›„ {len(values)}ê°œ ë°ì´í„° ì‚¬ìš© (ì›ë˜ {original_count}ê°œ)"
                        )

                # ë¶„í¬ ë¶„ì„
                analysis = self.analyze_distribution(values)
                monthly_analysis[month] = analysis

                # ìµœì í™”ëœ ê¸°ì¤€ê°’ ê³„ì‚°
                if analysis["method"] == "trimmed_mean":
                    reference_val = self.calculate_trimmed_mean(values)
                    variability = np.std(values)  # í‘œì¤€í¸ì°¨
                    method_label = "ì ˆì‚­í‰ê· "
                elif analysis["method"] == "median":
                    reference_val = np.median(values)
                    # IQR ì‚¬ìš©
                    q1 = np.percentile(values, 25)
                    q3 = np.percentile(values, 75)
                    variability = q3 - q1
                    method_label = "ì¤‘ì•™ê°’"
                elif analysis["method"] == "mad_adjusted":
                    reference_val = self.calculate_mad_adjusted_center(values)
                    # MAD ì‚¬ìš©
                    median_val = np.median(values)
                    variability = np.median(np.abs(values - median_val))
                    method_label = "MADì¡°ì •"
                else:  # fallback
                    reference_val = np.median(values)
                    variability = np.std(values)
                    method_label = "ì¤‘ì•™ê°’(ê¸°ë³¸)"

                monthly_references[month] = round(reference_val, 2)
                monthly_variabilities[month] = round(variability, 2)

                # ìƒì„¸ ë¶„ì„ ì •ë³´ ì¶œë ¥
                print(
                    f"      ğŸ“Š {month}: {method_label} = {reference_val:.2f} (Â±{variability:.2f})"
                )
                print(f"         - ë¶„ì„ê·¼ê±°: {analysis['reason']}")
                print(
                    f"         - ì •ê·œì„± p-value: {analysis['normality_p']:.4f}"
                    if analysis["normality_p"]
                    else ""
                )
                print(
                    f"         - ì¹˜ìš°ì¹¨: {analysis['skewness']:.3f}"
                    if analysis["skewness"]
                    else ""
                )
                print(
                    f"         - MAD ë¹„ìœ¨: {analysis['mad_ratio']:.3f}"
                    if analysis["mad_ratio"]
                    else ""
                )
                print(f"         - ë°ì´í„° ê°œìˆ˜: {len(values)}ê°œ")

        return monthly_references, monthly_variabilities, monthly_analysis

    def calculate_monthly_stats_with_outlier_removal(
        self, usage_patterns, remove_outliers=False
    ):
        """
        ì ì‘í˜• í†µê³„ ê³„ì‚°ì„ ì‚¬ìš©í•˜ë„ë¡ ì—…ë°ì´íŠ¸ëœ ë©”ì„œë“œ
        (ê¸°ì¡´ í˜¸í™˜ì„±ì„ ìœ„í•´ ìœ ì§€)

        Args:
            usage_patterns (list): ì‚¬ìš©ëŸ‰ íŒ¨í„´ ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸
            remove_outliers (bool): ì´ìƒì¹˜ ì œê±° ì—¬ë¶€

        Returns:
            tuple: (ì›”ë³„ ê¸°ì¤€ê°’, ì›”ë³„ ë³€ë™ì„± ì§€í‘œ)
        """
        references, variabilities, _ = self.calculate_adaptive_monthly_stats(
            usage_patterns, remove_outliers
        )
        return references, variabilities

    def calculate_monthly_stats(self, usage_patterns):
        """
        ì—¬ëŸ¬ ì‚¬ìš©ëŸ‰ íŒ¨í„´ì˜ ì›”ë³„ í†µê³„ë¥¼ ê³„ì‚°

        Args:
            usage_patterns (list): ì‚¬ìš©ëŸ‰ íŒ¨í„´ ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸

        Returns:
            tuple: (ì›”ë³„ ê¸°ì¤€ê°’, ì›”ë³„ ë³€ë™ì„± ì§€í‘œ)
        """
        return self.calculate_monthly_stats_with_outlier_removal(
            usage_patterns, remove_outliers=False
        )

    def check_group_combinations(self, group_columns):
        """
        ê·¸ë£¹í™”í•  ì»¬ëŸ¼ë“¤ì˜ ê³ ìœ í•œ ì¡°í•© ê°œìˆ˜ì™€ ë‚´ìš©ì„ í™•ì¸

        Args:
            group_columns (list): ê·¸ë£¹í™”í•  ì»¬ëŸ¼ëª… ë¦¬ìŠ¤íŠ¸
        """
        if self.df is None:
            print("ë°ì´í„°ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return

        # ê³ ìœ í•œ ì¡°í•© í™•ì¸
        unique_combinations = self.df[group_columns].drop_duplicates()
        combination_count = len(unique_combinations)

        print(f"\nğŸ“Š ê·¸ë£¹í™” ì¡°í•© ë¶„ì„:")
        print(f"   - ê·¸ë£¹í™” ê¸°ì¤€: {', '.join(group_columns)}")
        print(f"   - ì´ ê³ ìœ í•œ ì¡°í•© ê°œìˆ˜: {combination_count}ê°œ")

        # ê° ì»¬ëŸ¼ë³„ ê³ ìœ ê°’ ê°œìˆ˜ë„ í‘œì‹œ
        for col in group_columns:
            unique_values = self.df[col].nunique()
            print(f"   - '{col}' ê³ ìœ ê°’ ê°œìˆ˜: {unique_values}ê°œ")

        # ì¡°í•©ì´ ë„ˆë¬´ ë§ì§€ ì•Šìœ¼ë©´ ì¼ë¶€ ì˜ˆì‹œ í‘œì‹œ
        if combination_count <= 20:
            print(f"\nğŸ“‹ ëª¨ë“  ì¡°í•©:")
            for idx, (_, row) in enumerate(unique_combinations.iterrows(), 1):
                combo_str = " | ".join([f"{col}: {row[col]}" for col in group_columns])
                # ê° ì¡°í•©ë³„ ë°ì´í„° ê°œìˆ˜ë„ í‘œì‹œ
                count = len(
                    self.df[(self.df[group_columns] == row[group_columns]).all(axis=1)]
                )
                print(f"   [{idx:2d}] {combo_str} ({count}ê°œ ë°ì´í„°)")
        else:
            print(f"\nğŸ“‹ ì¡°í•© ì˜ˆì‹œ (ì²˜ìŒ 10ê°œ):")
            for idx, (_, row) in enumerate(unique_combinations.head(10).iterrows(), 1):
                combo_str = " | ".join([f"{col}: {row[col]}" for col in group_columns])
                count = len(
                    self.df[(self.df[group_columns] == row[group_columns]).all(axis=1)]
                )
                print(f"   [{idx:2d}] {combo_str} ({count}ê°œ ë°ì´í„°)")
            print(f"   ... (ì´ {combination_count}ê°œ ì¡°í•©)")

        return combination_count

    def create_heat_group_column(self):
        """
        ì—´ëŸ‰ ì»¬ëŸ¼ì„ ê¸°ë°˜ìœ¼ë¡œ ì—´ëŸ‰ ë²”ìœ„ ê·¸ë£¹ì„ ìƒì„±í•˜ê³ ,
        'ì—´ëŸ‰ë²”ìœ„_ê·¸ë£¹_ìš©ë„' í˜•íƒœì˜ ìƒˆë¡œìš´ ì»¬ëŸ¼ì„ ì¶”ê°€
        """
        if self.df is None:
            print("ë°ì´í„°ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return False

        # í•„ìš”í•œ ì»¬ëŸ¼ë“¤ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
        required_columns = ["ì—´ëŸ‰", "ê·¸ë£¹", "ìš©ë„"]
        missing_columns = [
            col for col in required_columns if col not in self.df.columns
        ]

        if missing_columns:
            print(f"í•„ìš”í•œ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤: {missing_columns}")
            return False

        # ì—´ëŸ‰ ë²”ìœ„ ê·¸ë£¹ ìƒì„±
        self.df["ì—´ëŸ‰ë²”ìœ„"] = self.df["ì—´ëŸ‰"].apply(
            lambda x: get_heat_input_gt(x) if pd.notna(x) else "Unknown"
        )

        # ì—´ëŸ‰ë²”ìœ„_ê·¸ë£¹_ìš©ë„ ì¡°í•© ì»¬ëŸ¼ ìƒì„±
        self.df["ì—´ëŸ‰ë²”ìœ„_ê·¸ë£¹_ìš©ë„"] = (
            self.df["ì—´ëŸ‰ë²”ìœ„"].astype(str)
            + "_"
            + self.df["ê·¸ë£¹"].astype(str)
            + "_"
            + self.df["ìš©ë„"].astype(str)
        )

        print(f"âœ… ì—´ëŸ‰ ë²”ìœ„ ê·¸ë£¹í™” ì™„ë£Œ")
        print(f"   - ìƒì„±ëœ ì—´ëŸ‰ ë²”ìœ„: {self.df['ì—´ëŸ‰ë²”ìœ„'].value_counts().to_dict()}")

        return True

    # ìš©ë„ë³„ í‰ê· !!!!

    def group_and_calculate(self, group_columns=["ê·¸ë£¹", "ìš©ë„"]):
        """
        ì§€ì •ëœ ì»¬ëŸ¼ë“¤ì„ ê¸°ì¤€ìœ¼ë¡œ ê·¸ë£¹í™”í•˜ê³  ì ì‘í˜• í†µê³„ ê³„ì‚°

        Args:
            group_columns (list): ê·¸ë£¹í™”í•  ì»¬ëŸ¼ëª… ë¦¬ìŠ¤íŠ¸

        Returns:
            pd.DataFrame: ê·¸ë£¹í™”ëœ ê²°ê³¼ ë°ì´í„°í”„ë ˆì„
        """
        if self.df is None:
            print("ë°ì´í„°ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return None

        # í•„ìš”í•œ ì»¬ëŸ¼ë“¤ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
        required_columns = group_columns + ["ì‚¬ìš©ëŸ‰_íŒ¨í„´"]
        missing_columns = [
            col for col in required_columns if col not in self.df.columns
        ]

        if missing_columns:
            print(f"í•„ìš”í•œ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤: {missing_columns}")
            return None

        # ê·¸ë£¹ë³„ë¡œ ë°ì´í„° ì²˜ë¦¬
        grouped_results = []

        for group_value, group_df in self.df.groupby(group_columns):
            # ë‹¤ì¤‘ ì»¬ëŸ¼ ê·¸ë£¹í™”ì˜ ê²½ìš° group_valueê°€ íŠœí”Œì´ë¯€ë¡œ ì²˜ë¦¬
            if isinstance(group_value, tuple):
                group_info = dict(zip(group_columns, group_value))
            else:
                group_info = {group_columns[0]: group_value}

            print(f"\nğŸ” ê·¸ë£¹ ë¶„ì„ ì¤‘: {group_info}")

            # ì‚¬ìš©ëŸ‰ íŒ¨í„´ íŒŒì‹± ë° ì ì‘í˜• í†µê³„ ê³„ì‚°
            usage_patterns = []
            for pattern in group_df["ì‚¬ìš©ëŸ‰_íŒ¨í„´"]:
                parsed_pattern = self.parse_usage_pattern(pattern)
                if parsed_pattern:
                    usage_patterns.append(parsed_pattern)

            # ì›”ë³„ ì ì‘í˜• ê¸°ì¤€ê°’ê³¼ ë³€ë™ì„± ì§€í‘œ ê³„ì‚°
            monthly_references, monthly_variabilities, monthly_analysis = (
                self.calculate_adaptive_monthly_stats(usage_patterns)
            )

            # ê²°ê³¼ ì €ì¥ (ê·¸ë£¹ ì •ë³´ì™€ í†µê³„ ì •ë³´ í¬í•¨)
            result_dict = group_info.copy()
            result_dict.update(
                {
                    "ì‚¬ìš©ëŸ‰ íŒ¨í„´ ê¸°ì¤€ê°’": monthly_references,
                    "ì‚¬ìš©ëŸ‰ íŒ¨í„´ ë³€ë™ì„±": monthly_variabilities,
                    "ë¶„í¬ ë¶„ì„ ì •ë³´": monthly_analysis,
                    "ë°ì´í„° ê°œìˆ˜": len(group_df),
                }
            )
            grouped_results.append(result_dict)

        # ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜
        self.grouped_data = pd.DataFrame(grouped_results)

        print(f"\nâœ… ê·¸ë£¹í™” ì™„ë£Œ: {len(self.grouped_data)}ê°œ ê·¸ë£¹")
        print(f"ê·¸ë£¹í™” ê¸°ì¤€: {', '.join(group_columns)}")
        return self.grouped_data

    def group_and_calculate_with_heat(self, group_columns=["ì—´ëŸ‰ë²”ìœ„", "ê·¸ë£¹", "ìš©ë„"]):
        """
        ì—´ëŸ‰ ë²”ìœ„ë¥¼ í¬í•¨í•œ ì§€ì •ëœ ì»¬ëŸ¼ë“¤ì„ ê¸°ì¤€ìœ¼ë¡œ ê·¸ë£¹í™”í•˜ê³  ì ì‘í˜• í†µê³„ ê³„ì‚°

        Args:
            group_columns (list): ê·¸ë£¹í™”í•  ì»¬ëŸ¼ëª… ë¦¬ìŠ¤íŠ¸

        Returns:
            pd.DataFrame: ê·¸ë£¹í™”ëœ ê²°ê³¼ ë°ì´í„°í”„ë ˆì„
        """
        if self.df is None:
            print("ë°ì´í„°ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return None

        # ì—´ëŸ‰ ë²”ìœ„ ì»¬ëŸ¼ ìƒì„±
        if not self.create_heat_group_column():
            return None

        # í•„ìš”í•œ ì»¬ëŸ¼ë“¤ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
        required_columns = group_columns + ["ì‚¬ìš©ëŸ‰_íŒ¨í„´"]
        missing_columns = [
            col for col in required_columns if col not in self.df.columns
        ]

        if missing_columns:
            print(f"í•„ìš”í•œ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤: {missing_columns}")
            return None

        # ê·¸ë£¹ë³„ë¡œ ë°ì´í„° ì²˜ë¦¬
        grouped_results = []

        for group_value, group_df in self.df.groupby(group_columns):
            # ë‹¤ì¤‘ ì»¬ëŸ¼ ê·¸ë£¹í™”ì˜ ê²½ìš° group_valueê°€ íŠœí”Œì´ë¯€ë¡œ ì²˜ë¦¬
            if isinstance(group_value, tuple):
                group_info = dict(zip(group_columns, group_value))
            else:
                group_info = {group_columns[0]: group_value}

            print(f"\nğŸ” ê·¸ë£¹ ë¶„ì„ ì¤‘: {group_info}")

            # ì‚¬ìš©ëŸ‰ íŒ¨í„´ íŒŒì‹± ë° ì ì‘í˜• í†µê³„ ê³„ì‚°
            usage_patterns = []
            for pattern in group_df["ì‚¬ìš©ëŸ‰_íŒ¨í„´"]:
                parsed_pattern = self.parse_usage_pattern(pattern)
                if parsed_pattern:
                    usage_patterns.append(parsed_pattern)

            # ì›”ë³„ ì ì‘í˜• ê¸°ì¤€ê°’ê³¼ ë³€ë™ì„± ì§€í‘œ ê³„ì‚°
            monthly_references, monthly_variabilities, monthly_analysis = (
                self.calculate_adaptive_monthly_stats(usage_patterns)
            )

            # ê²°ê³¼ ì €ì¥ (ê·¸ë£¹ ì •ë³´ì™€ í†µê³„ ì •ë³´ í¬í•¨)
            result_dict = group_info.copy()
            result_dict.update(
                {
                    "ì‚¬ìš©ëŸ‰ íŒ¨í„´ ê¸°ì¤€ê°’": monthly_references,
                    "ì‚¬ìš©ëŸ‰ íŒ¨í„´ ë³€ë™ì„±": monthly_variabilities,
                    "ë¶„í¬ ë¶„ì„ ì •ë³´": monthly_analysis,
                    "ë°ì´í„° ê°œìˆ˜": len(group_df),
                }
            )
            grouped_results.append(result_dict)

        # ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜
        self.grouped_data = pd.DataFrame(grouped_results)

        print(f"\nâœ… ê·¸ë£¹í™” ì™„ë£Œ: {len(self.grouped_data)}ê°œ ê·¸ë£¹")
        print(f"ê·¸ë£¹í™” ê¸°ì¤€: {', '.join(group_columns)}")
        return self.grouped_data

    def display_results(self):
        """
        ê·¸ë£¹í™” ê²°ê³¼ë¥¼ í™”ë©´ì— ì¶œë ¥ (ì ì‘í˜• í†µê³„ ì§€ì›)
        """
        if self.grouped_data is None:
            print("ê·¸ë£¹í™”ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        print(f"\n{'='*80}")
        print(f"                    ì ì‘í˜• í†µê³„ ê¸°ë°˜ ê·¸ë£¹í™” ê²°ê³¼")
        print(f"{'='*80}")

        for idx, (_, row) in enumerate(self.grouped_data.iterrows(), 1):
            # ê·¸ë£¹ ì •ë³´ ì¶”ì¶œ (í†µê³„ ê´€ë ¨ ì»¬ëŸ¼ ì œì™¸)
            group_info = {}
            for col in self.grouped_data.columns:
                if col not in [
                    "ì‚¬ìš©ëŸ‰ íŒ¨í„´ ê¸°ì¤€ê°’",
                    "ì‚¬ìš©ëŸ‰ íŒ¨í„´ ë³€ë™ì„±",
                    "ë¶„í¬ ë¶„ì„ ì •ë³´",
                    "ë°ì´í„° ê°œìˆ˜",
                ]:
                    group_info[col] = row[col]

            print(f"\n[{idx}] ", end="")
            group_parts = [f"{k}: {v}" for k, v in group_info.items()]
            print(" | ".join(group_parts))

            # ë°ì´í„° ê°œìˆ˜ ì •ë³´ ì¶”ê°€
            if "ë°ì´í„° ê°œìˆ˜" in row:
                print(f"     ğŸ“Š ë°ì´í„° ê°œìˆ˜: {row['ë°ì´í„° ê°œìˆ˜']}ê°œ")

            print("-" * 60)

            monthly_reference_data = row["ì‚¬ìš©ëŸ‰ íŒ¨í„´ ê¸°ì¤€ê°’"]
            monthly_variability_data = row["ì‚¬ìš©ëŸ‰ íŒ¨í„´ ë³€ë™ì„±"]
            monthly_analysis_data = row.get("ë¶„í¬ ë¶„ì„ ì •ë³´", {})

            if isinstance(monthly_reference_data, dict) and isinstance(
                monthly_variability_data, dict
            ):
                print(f"ğŸ“ˆ ì›”ë³„ ì ì‘í˜• ê¸°ì¤€ê°’ ë° ë³€ë™ì„±:")

                # ë¶„ê¸°ë³„ë¡œ ë‚˜ëˆ„ì–´ ì¶œë ¥
                quarters = [
                    ["1ì›”", "2ì›”", "3ì›”"],  # 1ë¶„ê¸°
                    ["4ì›”", "5ì›”", "6ì›”"],  # 2ë¶„ê¸°
                    ["7ì›”", "8ì›”", "9ì›”"],  # 3ë¶„ê¸°
                    ["10ì›”", "11ì›”", "12ì›”"],  # 4ë¶„ê¸°
                ]

                for quarter_idx, quarter in enumerate(quarters, 1):
                    quarter_data = []
                    for month in quarter:
                        ref_val = monthly_reference_data.get(month, 0)
                        var_val = monthly_variability_data.get(month, 0)

                        # ë¶„ì„ ì •ë³´ì—ì„œ ì‚¬ìš©ëœ ë°©ë²• í™•ì¸
                        method_info = monthly_analysis_data.get(month, {})
                        method = method_info.get("method", "unknown")

                        # ë°©ë²•ë³„ í‘œì‹œ ê¸°í˜¸
                        method_symbol = {
                            "trimmed_mean": "ğŸ”¹",  # ì ˆì‚­í‰ê· 
                            "median": "ğŸ”¸",  # ì¤‘ì•™ê°’
                            "mad_adjusted": "ğŸ”¶",  # MADì¡°ì •
                        }.get(method, "âšª")

                        quarter_data.append(
                            f"{method_symbol}{month}: {ref_val:>7.2f}(Â±{var_val:>6.2f})"
                        )

                    print(f"   {quarter_idx}ë¶„ê¸°: {' | '.join(quarter_data)}")

                # ë²”ë¡€ í‘œì‹œ
                print(f"\n   ğŸ“‹ ë²”ë¡€: ğŸ”¹ì ˆì‚­í‰ê·  ğŸ”¸ì¤‘ì•™ê°’ ğŸ”¶MADì¡°ì •")

                # ë¶„í¬ ë¶„ì„ ìš”ì•½ í‘œì‹œ
                if monthly_analysis_data:
                    print(f"\n   ğŸ” ë¶„í¬ ë¶„ì„ ìš”ì•½:")
                    method_counts = {}
                    for month_info in monthly_analysis_data.values():
                        method = month_info.get("method", "unknown")
                        reason = month_info.get("reason", "unknown")
                        method_counts[f"{method} ({reason})"] = (
                            method_counts.get(f"{method} ({reason})", 0) + 1
                        )

                    for method_reason, count in method_counts.items():
                        print(f"      - {method_reason}: {count}ê°œì›”")

        print(f"\n{'='*80}")
        print(f"ğŸ’¡ ì ì‘í˜• í†µê³„ ì„¤ëª…:")
        print(f"   - ì ˆì‚­í‰ê· : ì •ê·œë¶„í¬ì— ê°€ê¹Œìš´ ë°ì´í„°ì— ì‚¬ìš© (ìƒí•˜ìœ„ 10% ì œì™¸)")
        print(f"   - ì¤‘ì•™ê°’: ì¹˜ìš°ì¹œ ë¶„í¬ ë°ì´í„°ì— ì‚¬ìš© (ë³€ë™ì„±=IQR)")
        print(f"   - MADì¡°ì •: ë³€ë™ì„±ì´ í° ë°ì´í„°ì— ì‚¬ìš© (MAD ê¸°ë°˜ robust ì¤‘ì‹¬ê°’)")
        print(f"{'='*80}")


def convert_df_to_dict(obj):
    if isinstance(obj, pd.DataFrame):
        return obj.to_dict()
    elif isinstance(obj, list):
        return [convert_df_to_dict(item) for item in obj]
    elif isinstance(obj, dict):
        return {k: convert_df_to_dict(v) for k, v in obj.items()}
    else:
        return obj


# ìš©ë„ ë³„ ê·¸ë£¹í™”
def main(input_file, output_file, group_columns, gt_json_path):
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    # í”„ë¡œì„¸ì„œ ì´ˆê¸°í™”
    processor = ExcelGroupProcessor(input_file)

    # ë°ì´í„° ë¡œë“œ
    if not processor.load_data():
        return

    # ê·¸ë£¹í™” ë° í‰ê· /í‘œì¤€í¸ì°¨ ê³„ì‚°
    result = processor.group_and_calculate(group_columns=group_columns)
    results_serializable = convert_df_to_dict(result)
    # JSON íŒŒì¼ë¡œ ì €ì¥

    with open(gt_json_path, "w", encoding="utf-8") as f:
        json.dump(results_serializable, f, ensure_ascii=False, indent=4)

    print(f"JSON íŒŒì¼ë¡œ ì €ì¥ ì™„ë£Œ: {gt_json_path}")

    return processor


# ì—´ëŸ‰ ë²”ìœ„ë¥¼ ê³ ë ¤í•œ ê·¸ë£¹í™”
def main_with_heat(input_file, output_file, group_columns, gt_json_path):
    """ì—´ëŸ‰ ë²”ìœ„ë¥¼ ê³ ë ¤í•œ ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    # í”„ë¡œì„¸ì„œ ì´ˆê¸°í™”
    processor = ExcelGroupProcessor(input_file)

    # ë°ì´í„° ë¡œë“œ
    if not processor.load_data():
        return

    # ì—´ëŸ‰ ë²”ìœ„ë¥¼ ê³ ë ¤í•œ ê·¸ë£¹í™” ë° í‰ê· /í‘œì¤€í¸ì°¨ ê³„ì‚°
    result = processor.group_and_calculate_with_heat(group_columns=group_columns)
    results_serializable = convert_df_to_dict(result)

    # JSON íŒŒì¼ë¡œ ì €ì¥
    with open(gt_json_path, "w", encoding="utf-8") as f:
        json.dump(results_serializable, f, ensure_ascii=False, indent=4)

    print(f"JSON íŒŒì¼ë¡œ ì €ì¥ ì™„ë£Œ: {gt_json_path}")

    return processor


if __name__ == "__main__":
    print("=" * 80)
    print("          Excel ë°ì´í„° ê·¸ë£¹í™” ë° í†µê³„ ë¶„ì„ í”„ë¡œê·¸ë¨")
    print("=" * 80)

    # ê¸°ë³¸ ì„¤ì •
    input_file = "./group_biz_with_12.xlsx"

    # ì—´ëŸ‰ ë²”ìœ„ë¥¼ ê³ ë ¤í•œ ê·¸ë£¹í™” ì‹¤í–‰
    print("\nğŸ”¥ ì—´ëŸ‰ ë²”ìœ„ë¥¼ ê³ ë ¤í•œ ê·¸ë£¹ê³¼ ìš©ë„ë³„ ê·¸ë£¹í™” ì‹¤í–‰...")
    output_file_heat = "./group_biz_with_usage_heat.xlsx"
    gt_json_path_heat = "./group_biz_with_usage_heat_optimize.json"
    group_columns_heat = ["ì—´ëŸ‰ë²”ìœ„", "ê·¸ë£¹", "ìš©ë„"]  # ì—´ëŸ‰ë²”ìœ„, ê·¸ë£¹, ìš©ë„ë¡œ ê·¸ë£¹í™”
    processor_heat = main_with_heat(
        input_file, output_file_heat, group_columns_heat, gt_json_path_heat
    )

    if processor_heat:
        print("âœ… ì—´ëŸ‰ ë²”ìœ„ë¥¼ ê³ ë ¤í•œ ê·¸ë£¹ê³¼ ìš©ë„ë³„ ê·¸ë£¹í™” ì™„ë£Œ")
        processor_heat.display_results()

    print("\n" + "=" * 80)
    print("           ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤! ğŸ‰")
    print("=" * 80)
