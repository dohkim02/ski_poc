import pandas as pd
import numpy as np
from datetime import datetime
import json
from concurrent.futures import ThreadPoolExecutor
from utils import MonthlyAverageAnalyzer
import os
import sys
from utils import categorize_pressure, clean_column_names, get_exel_with_biz_lst

data_path = os.path.abspath("../")  # ì˜ˆ: í•œ ë‹¨ê³„ ë°”ê¹¥ í´ë”
sys.path.append(data_path)

# 1ï¸âƒ£ ë°ì´í„° ë¡œë”©
file_path = "../data2_whole.xlsx"


# í•„ìš”í•œ ì»¬ëŸ¼ ë°ì´í„°ë§Œ ë½‘ê¸°
def preprocess_excel(file_path, output_path):
    # 1. ì—‘ì…€ íŒŒì¼ ì½ê¸°
    df = pd.read_excel(file_path)
    df = clean_column_names(df)

    # ğŸ” ë””ë²„ê¹…: ì›ë³¸ ì»¬ëŸ¼ ì •ë³´ ì¶œë ¥
    print(f"ğŸ“Š ì›ë³¸ ë°ì´í„° ì •ë³´:")
    print(f"   - ì´ í–‰ ìˆ˜: {len(df)}")
    print(f"   - ì´ ì»¬ëŸ¼ ìˆ˜: {len(df.columns)}")
    print(f"   - ì»¬ëŸ¼ íƒ€ì…ë“¤:")
    for i, col in enumerate(df.columns[:10]):  # ì²˜ìŒ 10ê°œë§Œ ì¶œë ¥
        print(f"     [{i+1}] {col} ({type(col).__name__})")
    if len(df.columns) > 10:
        print(f"     ... ì´ {len(df.columns)}ê°œ ì»¬ëŸ¼")

    # 2. ê¸°ë³¸ ì»¬ëŸ¼ ì •ì˜
    base_cols = ["êµ¬ë¶„", "ì—…íƒœ", "ì—…ì¢…", "ìš©ë„", "ë“±ê¸‰", "ì••ë ¥"]

    # 3. ì‹œê°„ ì»¬ëŸ¼ íŒë³„ (datetime í˜•ì‹)
    time_cols = [col for col in df.columns if isinstance(col, datetime)]

    # ğŸ” ë””ë²„ê¹…: ì‹œê°„ ì»¬ëŸ¼ ì •ë³´ ì¶œë ¥
    print(f"\nğŸ• ì‹œê°„ ì»¬ëŸ¼ ë¶„ì„:")
    print(f"   - datetime íƒ€ì… ì»¬ëŸ¼ ê°œìˆ˜: {len(time_cols)}")
    if time_cols:
        print(f"   - ì‹œê°„ ì»¬ëŸ¼ë“¤:")
        for i, col in enumerate(time_cols[:5]):  # ì²˜ìŒ 5ê°œë§Œ ì¶œë ¥
            print(f"     [{i+1}] {col}")
        if len(time_cols) > 5:
            print(f"     ... ì´ {len(time_cols)}ê°œ ì‹œê°„ ì»¬ëŸ¼")
    else:
        print("   âš ï¸ datetime íƒ€ì… ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤!")
        print("   ğŸ“ ë‹¤ë¥¸ í˜•íƒœì˜ ë‚ ì§œ ì»¬ëŸ¼ì„ ì°¾ì•„ë³´ê² ìŠµë‹ˆë‹¤...")

        # ë‚ ì§œ í˜•íƒœë¡œ ë³´ì´ëŠ” ì»¬ëŸ¼ ì°¾ê¸°
        date_like_cols = []
        for col in df.columns:
            if isinstance(col, str):
                # 22.04, 2022.04, 22-04 ë“±ì˜ íŒ¨í„´ ì°¾ê¸°
                import re

                if re.match(r"\d{2}[.\-]\d{2}", str(col)) or re.match(
                    r"\d{4}[.\-]\d{2}", str(col)
                ):
                    date_like_cols.append(col)

        if date_like_cols:
            print(f"   ğŸ’¡ ë‚ ì§œ í˜•íƒœë¡œ ë³´ì´ëŠ” ì»¬ëŸ¼ë“¤ ë°œê²¬: {len(date_like_cols)}ê°œ")
            for col in date_like_cols[:5]:
                print(f"     - {col}")
            print("   ğŸ”§ ì´ ì»¬ëŸ¼ë“¤ì„ ì‹œê°„ ì»¬ëŸ¼ìœ¼ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

        # ìˆ«ìë¡œë§Œ ëœ ì»¬ëŸ¼ë“¤ë„ í™•ì¸ (ë‚ ì§œì¼ ê°€ëŠ¥ì„±)
        numeric_cols = [col for col in df.columns if isinstance(col, (int, float))]
        if numeric_cols:
            print(f"   ğŸ”¢ ìˆ«ì íƒ€ì… ì»¬ëŸ¼ë“¤: {len(numeric_cols)}ê°œ")
            for col in numeric_cols[:5]:
                print(f"     - {col}")

    # 4. ì—…íƒœ ë˜ëŠ” ì—…ì¢… ê²°ì¸¡ ì œê±°
    df = df.dropna(subset=["ì—…íƒœ", "ì—…ì¢…"])

    # 5. ë“±ê¸‰ ì»¬ëŸ¼ ê²°ì¸¡ â†’ 0
    fill_zero_cols = ["ë“±ê¸‰", "ì••ë ¥"] + time_cols
    df[fill_zero_cols] = df[fill_zero_cols].fillna(0)

    # ğŸ” ë””ë²„ê¹…: time_colsê°€ ë¹„ì–´ìˆìœ¼ë©´ ê²½ê³ 
    if not time_cols:
        print(
            f"\nâŒ ê²½ê³ : ì‹œê°„ ì»¬ëŸ¼ì´ ì—†ì–´ì„œ 'ì‚¬ìš©ëŸ‰_íŒ¨í„´'ê³¼ '3ë…„ì¹˜ ë°ì´í„°'ê°€ ë¹„ì–´ìˆê²Œ ë©ë‹ˆë‹¤!"
        )
        print(f"   í•´ê²°ë°©ë²•:")
        print(f"   1. ì›ë³¸ ì—‘ì…€ íŒŒì¼ì˜ ì»¬ëŸ¼ì´ datetime í˜•ì‹ì¸ì§€ í™•ì¸")
        print(f"   2. ë‚ ì§œ ì»¬ëŸ¼ì„ ìˆ˜ë™ìœ¼ë¡œ ì§€ì •")
        print(f"   3. ë°ì´í„° í˜•íƒœë¥¼ í™•ì¸í•˜ì—¬ ì ì ˆí•œ ë³€í™˜ ìˆ˜í–‰")

        # ë¹ˆ ë°ì´í„°ë¡œ ì²˜ë¦¬
        df["3ë…„ì¹˜ ë°ì´í„°"] = [{}] * len(df)
        df["ì‚¬ìš©ëŸ‰_íŒ¨í„´"] = [{}] * len(df)
    else:
        # 6. 3ë…„ì¹˜ ë°ì´í„°ë¥¼ yearly_data í˜•íƒœë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜
        def get_yearly_data(row):
            # ì‹œê°„ ì»¬ëŸ¼ë“¤ì„ yy.mm í˜•íƒœë¡œ ë³€í™˜í•˜ê³  ê°’ë“¤ì„ ê°€ì ¸ì˜´
            time_data = {col.strftime("%y.%m"): row[col] for col in time_cols}

            # yearly_data í˜•íƒœë¡œ ë³€í™˜ (ë…„ë„ë³„ë¡œ ê·¸ë£¹í™”)
            yearly_data = {}
            for key, value in time_data.items():
                year, month = key.split(".")
                if year not in yearly_data:
                    yearly_data[year] = {}
                yearly_data[year][month] = value

            return yearly_data

        # 7. 3ë…„ì¹˜ ë°ì´í„° ì»¬ëŸ¼ ìƒì„±
        df["3ë…„ì¹˜ ë°ì´í„°"] = df.apply(get_yearly_data, axis=1)

        # 8. ì‚¬ìš©ëŸ‰_íŒ¨í„´ ìƒì„± (ì›”ë³„ í‰ê· ê°’ ë”•ì…”ë„ˆë¦¬)
        def get_monthly_avg(row):
            periods = [col.strftime("%y.%m") for col in time_cols]
            values = [row[col] for col in time_cols]
            analyzer = MonthlyAverageAnalyzer()
            analyzer.load_data(periods, values)
            monthly = analyzer.calculate_monthly_averages()

            # {'1ì›”': avg1, '2ì›”': avg2, ...} í˜•íƒœë¡œ ì €ì¥
            return dict(zip(monthly["month_name"], monthly["average"]))

        df["ì‚¬ìš©ëŸ‰_íŒ¨í„´"] = df.apply(get_monthly_avg, axis=1)

    df["ì••ë ¥_ê·¸ë£¹"] = df["ì••ë ¥"].apply(categorize_pressure)

    # 9. ì €ì¥í•  ê²°ê³¼ë§Œ ì¶”ì¶œ (3ë…„ì¹˜ ë°ì´í„° ì»¬ëŸ¼ í¬í•¨)
    df_result = df[base_cols + ["ì••ë ¥_ê·¸ë£¹", "ì‚¬ìš©ëŸ‰_íŒ¨í„´", "3ë…„ì¹˜ ë°ì´í„°"]]

    # ğŸ” ë””ë²„ê¹…: ê²°ê³¼ ë°ì´í„° í™•ì¸
    print(f"\nâœ… ì²˜ë¦¬ ê²°ê³¼:")
    print(f"   - ì²˜ë¦¬ëœ í–‰ ìˆ˜: {len(df_result)}")
    print(f"   - ì‚¬ìš©ëŸ‰_íŒ¨í„´ ìƒ˜í”Œ:")
    sample_pattern = df_result["ì‚¬ìš©ëŸ‰_íŒ¨í„´"].iloc[0] if len(df_result) > 0 else {}
    print(f"     {sample_pattern}")
    print(f"   - 3ë…„ì¹˜ ë°ì´í„° ìƒ˜í”Œ:")
    sample_yearly = df_result["3ë…„ì¹˜ ë°ì´í„°"].iloc[0] if len(df_result) > 0 else {}
    print(f"     {str(sample_yearly)[:100]}...")

    df_result.to_excel(output_path, index=False)

    print(f"âœ… ì²˜ë¦¬ ì™„ë£Œ: {output_path}")
    return output_path


# í´ëŸ¬í„°ë§ í•  ì²­í¬ ê°¯ìˆ˜ ì •í•˜ê¸°
def chunk_list(data_list, chunk_size=10):
    return [data_list[i : i + chunk_size] for i in range(0, len(data_list), chunk_size)]


# ì²­í¬ ë°ì´í„° ì“°ê¸°
def write_chunk_line(file_path, chunk, lock):
    line = json.dumps(chunk, ensure_ascii=False)
    # ìŠ¤ë ˆë“œê°€ ë™ì‹œì— íŒŒì¼ì— ì“°ì§€ ì•Šë„ë¡ ë½ì„ ì‚¬ìš©!
    with lock:
        with open(file_path, "a", encoding="utf-8") as f:
            f.write(line + "\n")


# ì—…íƒœ ì—…ì¢… ë½‘ê³ , ì €ì¥
def get_category_list(file_path, output_file="./category_list.txt", chunk_size=10):
    import threading

    # 1ï¸âƒ£ ì—‘ì…€ ì½ê¸°
    df = pd.read_excel(file_path)

    # 2ï¸âƒ£ 'ì—…íƒœ'ì™€ 'ì—…ì¢…' ì»¬ëŸ¼ë§Œ ì„ íƒ
    df_selected = df[["ì—…íƒœ", "ì—…ì¢…"]]

    # 3ï¸âƒ£ JSON ë³€í™˜
    data_list = json.loads(df_selected.to_json(orient="records", force_ascii=False))

    # 3ï¸âƒ£ 10ê°œì”© chunkë¡œ ë‚˜ëˆ„ê¸°
    chunked_data = chunk_list(data_list, chunk_size)

    # 4ï¸âƒ£ (ì“°ê¸° ì „ì— ê¸°ì¡´ íŒŒì¼ ì‚­ì œ)
    with open(output_file, "w", encoding="utf-8") as f:
        pass  # ë¹ˆ íŒŒì¼ë¡œ ì´ˆê¸°í™”

    # 5ï¸âƒ£ ë©€í‹°ìŠ¤ë ˆë”©ìœ¼ë¡œ ê° ì²­í¬ë¥¼ íŒŒì¼ì— í•œ ì¤„ì”© ê¸°ë¡
    lock = threading.Lock()
    with ThreadPoolExecutor() as executor:
        for chunk in chunked_data:
            executor.submit(write_chunk_line, output_file, chunk, lock)

    return chunked_data


output_path = "./preprocessed.xlsx"
# preprocess_excel(file_path, output_path)
# get_txt = get_category_list(output_path)

# ğŸ” ë””ë²„ê¹… í…ŒìŠ¤íŠ¸ ì‹¤í–‰
if __name__ == "__main__":
    print("=" * 60)
    print("ğŸ” ì „ì²˜ë¦¬ ë””ë²„ê¹… í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("=" * 60)
    preprocess_excel(file_path, output_path)
    print("=" * 60)
    print("ğŸ” ì „ì²˜ë¦¬ ë””ë²„ê¹… í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
    print("=" * 60)

# # # ì‚¬ìš© ì˜ˆì‹œ
# get_exel_with_biz_lst(
#     txt_path="./clustering_result.txt",
#     xlsx_path="./preprocessed.xlsx",
#     output_path="./group_biz_with_12.xlsx",
# )
# # ê²°ê³¼ í™•ì¸
# print(df_result.head())
# print(f"\nì „ì²˜ë¦¬ í›„ ë°ì´í„° ê°œìˆ˜: {len(df_result)}")
# print(f"ê²°ì¸¡ì¹˜ í™•ì¸:\n{df_result.isnull().sum()}")
